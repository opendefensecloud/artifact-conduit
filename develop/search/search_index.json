{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#what-is-artifact-conduit-arc","title":"What is Artifact Conduit (ARC)?","text":"<p>ARC (Artifact Conduit) is an open-source system that acts as a gateway for procuring various artifact types and transferring them across security zones while ensuring policy compliance through automated scanning and validation. The system addresses the challenge of bringing external artifacts\u2014container images, Helm charts, software packages, and other resources\u2014into restricted environments where direct internet access is prohibited.</p> <p>Primary Goals:</p> <ul> <li>Artifact Procurement: Pull artifacts from diverse sources including OCI registries, Helm repositories, S3-compatible storage, and HTTP endpoints</li> <li>Security Validation: Perform malware scanning, CVE analysis, license verification, and signature validation before artifact transfer</li> <li>Policy Enforcement: Ensure only artifacts meeting defined security and compliance policies cross security boundaries</li> <li>Declarative Management: Leverage Kubernetes-native declarative configuration for artifact lifecycle management</li> <li>Auditability: Provide attestation and traceability of all artifact processing operations</li> </ul> <p>Out of Scope: ARC does not replace existing registry solutions or artifact repositories. It functions as an orchestration layer that coordinates artifact transfer and validation between existing infrastructure components.</p>"},{"location":"#system-architecture","title":"System Architecture","text":"<p>ARC is implemented as a Kubernetes Extension API Server integrated with the Kubernetes API Aggregation Layer. This architectural approach provides several advantages over Custom Resource Definitions (CRDs), including dedicated storage isolation, custom API implementation flexibility, and reduced risk to the hosting cluster's control plane.</p> <pre><code>graph TB\n    subgraph \"User Layer\"\n        Users[\"Users/Operators\"]\n        arcctl[\"arcctl CLI&lt;br/&gt;cmd/arcctl/main.go\"]\n    end\n\n    subgraph \"Kubernetes Control Plane\"\n        K8sAPI[\"Kubernetes API Server&lt;br/&gt;API Aggregation Layer\"]\n    end\n\n    subgraph \"ARC Control Plane\"\n        ARCAPI[\"ARC API Server&lt;br/&gt;pkg/apiserver/&lt;br/&gt;Extension API Server\"]\n        etcdStore[\"Dedicated etcd&lt;br/&gt;Isolated Storage\"]\n        OrderCtrl[\"Order Controller&lt;br/&gt;pkg/controller/&lt;br/&gt;Reconciliation Logic\"]\n    end\n\n    subgraph \"API Resources (api/arc.bwi.de/v1alpha1)\"\n        Order[\"Order&lt;br/&gt;High-level request\"]\n        Fragment[\"Fragment&lt;br/&gt;Single artifact op\"]\n        Endpoint[\"Endpoint&lt;br/&gt;Source/Destination\"]\n        ATD[\"ArtifactTypeDefinition&lt;br/&gt;Type rules\"]\n    end\n\n    subgraph \"Execution Layer\"\n        ArgoWorkflows[\"Argo Workflows&lt;br/&gt;Workflow Execution\"]\n        WorkflowTemplates[\"WorkflowTemplate&lt;br/&gt;Processing Logic\"]\n    end\n\n    subgraph \"External Systems\"\n        OCIReg[\"OCI Registries\"]\n        HelmRepo[\"Helm Repositories\"]\n        S3Storage[\"S3 Compatible Storage\"]\n        Scanners[\"Security Scanners&lt;br/&gt;Trivy, ClamAV\"]\n    end\n\n    Users --&gt;|\"CLI commands\"| arcctl\n    arcctl --&gt;|\"API requests\"| K8sAPI\n\n    K8sAPI --&gt;|\"forwards arc.bwi.de/*\"| ARCAPI\n    ARCAPI --&gt;|\"stores/retrieves\"| etcdStore\n\n    OrderCtrl --&gt;|\"watches\"| etcdStore\n    OrderCtrl --&gt;|\"creates\"| Fragment\n    OrderCtrl --&gt;|\"creates\"| ArgoWorkflows\n\n    Order --&gt;|\"references\"| Endpoint\n    Order --&gt;|\"uses\"| ATD\n    Fragment --&gt;|\"references\"| Endpoint\n\n    ATD --&gt;|\"specifies\"| WorkflowTemplates\n    ArgoWorkflows --&gt;|\"instantiates\"| WorkflowTemplates\n\n    ArgoWorkflows --&gt;|\"pulls from\"| OCIReg\n    ArgoWorkflows --&gt;|\"pulls from\"| HelmRepo\n    ArgoWorkflows --&gt;|\"pulls from\"| S3Storage\n    ArgoWorkflows --&gt;|\"scans with\"| Scanners\n    ArgoWorkflows --&gt;|\"pushes to\"| OCIReg</code></pre> <p>Architecture: ARC System Components and Data Flow</p> <p>The system follows a layered architecture where users interact through the <code>arcctl</code> CLI tool, requests flow through the Kubernetes API aggregation layer to the ARC API Server, and the Order Controller orchestrates workflow execution by decomposing high-level Orders into executable Fragments.</p>"},{"location":"#core-concepts","title":"Core Concepts","text":"<p>ARC introduces four primary custom resource types under the <code>arc.bwi.de/v1alpha1</code> API group:</p> Resource Purpose Scope Order Declares intent to procure one or more artifacts with shared configuration defaults User-facing, high-level Fragment Represents a single artifact operation decomposed from an Order System-generated, execution unit Endpoint Defines a source or destination location with credentials Configuration, reusable ArtifactTypeDefinition Specifies processing rules and workflow templates for artifact types (e.g., \"oci\", \"helm\") Configuration, system-wide <pre><code>graph LR\n    subgraph \"Declarative Layer\"\n        Order[\"Order&lt;br/&gt;(User Input)\"]\n        OrderSpec[\"spec:&lt;br/&gt;- defaults&lt;br/&gt;- artifacts[]\"]\n    end\n\n    subgraph \"Generated Layer\"\n        Fragment1[\"Fragment-1\"]\n        Fragment2[\"Fragment-2\"]\n        FragmentN[\"Fragment-N\"]\n    end\n\n    subgraph \"Configuration\"\n        SrcEndpoint[\"Endpoint&lt;br/&gt;(Source)\"]\n        DstEndpoint[\"Endpoint&lt;br/&gt;(Destination)\"]\n        ATD[\"ArtifactTypeDefinition&lt;br/&gt;(e.g., 'oci')\"]\n        Secret[\"Secret&lt;br/&gt;(Credentials)\"]\n    end\n\n    subgraph \"Execution\"\n        WorkflowTemplate[\"WorkflowTemplate&lt;br/&gt;(Argo)\"]\n        Workflow1[\"Workflow Instance\"]\n        Workflow2[\"Workflow Instance\"]\n    end\n\n    Order --&gt;|\"contains\"| OrderSpec\n    OrderSpec --&gt;|\"generates\"| Fragment1\n    OrderSpec --&gt;|\"generates\"| Fragment2\n    OrderSpec --&gt;|\"generates\"| FragmentN\n\n    Fragment1 --&gt;|\"srcRef\"| SrcEndpoint\n    Fragment1 --&gt;|\"dstRef\"| DstEndpoint\n    Fragment1 --&gt;|\"type\"| ATD\n    Fragment2 --&gt;|\"references\"| SrcEndpoint\n    Fragment2 --&gt;|\"references\"| DstEndpoint\n\n    SrcEndpoint --&gt;|\"credentialRef\"| Secret\n    DstEndpoint --&gt;|\"credentialRef\"| Secret\n\n    ATD --&gt;|\"workflowTemplateRef\"| WorkflowTemplate\n    Fragment1 -.-&gt;|\"triggers\"| Workflow1\n    Fragment2 -.-&gt;|\"triggers\"| Workflow2\n    WorkflowTemplate -.-&gt;|\"instantiates\"| Workflow1\n    WorkflowTemplate -.-&gt;|\"instantiates\"| Workflow2</code></pre>"},{"location":"#key-components","title":"Key Components","text":""},{"location":"#arc-api-server","title":"ARC API Server","text":"<p>The ARC API Server is a Kubernetes Extension API Server implemented using the <code>k8s.io/apiserver</code> library. Key characteristics:</p> <ul> <li>Implementation Path: <code>pkg/apiserver/</code></li> <li>Storage Backend: Dedicated etcd instance (isolated from Kubernetes control plane etcd)</li> <li>Registry Pattern: Uses <code>pkg/registry/</code> for custom storage strategies per resource type</li> <li>API Group: <code>arc.bwi.de</code> with version <code>v1alpha1</code></li> <li>Integration: Registered with Kubernetes API Aggregation Layer to handle requests to <code>arc.bwi.de/*</code> paths</li> </ul> <p>The dedicated etcd approach provides:</p> <ul> <li>Isolation from the hosting cluster's control plane</li> <li>Flexibility to change storage backends if needed</li> <li>Protection against resource volume impacting cluster stability</li> </ul>"},{"location":"#order-controller","title":"Order Controller","text":"<p>The Order Controller implements the reconciliation loop for Order resources:</p> <ul> <li>Implementation Path: <code>pkg/controller/</code></li> <li>Framework: Uses <code>sigs.k8s.io/controller-runtime</code> (version 0.22.4)</li> <li> <p>Reconciliation Logic:</p> <ol> <li>Watch for Order create/update/delete events</li> <li>Validate endpoint references exist</li> <li>Apply defaults from Order.spec.defaults</li> <li>Generate Fragment resources (one per artifact entry)</li> <li>Lookup ArtifactTypeDefinition for each fragment's type</li> <li>Create Argo Workflow instances with appropriate WorkflowTemplate references</li> <li>Update Order status based on Fragment and Workflow statuses</li> <li>Handle finalizers for cleanup operations</li> </ol> </li> </ul> <pre><code>sequenceDiagram\n    participant User\n    participant arcctl\n    participant K8sAPI as \"Kubernetes API\"\n    participant ARCAPI as \"ARC API Server&lt;br/&gt;pkg/apiserver/\"\n    participant etcd as \"Dedicated etcd\"\n    participant OrderCtrl as \"Order Controller&lt;br/&gt;pkg/controller/\"\n    participant ArgoCtrl as \"Argo Controller\"\n    participant Workflow as \"Workflow Pod\"\n    participant Registry as \"External Registry\"\n\n    User-&gt;&gt;arcctl: \"arcctl oci pull alpine:3.18\"\n    arcctl-&gt;&gt;K8sAPI: \"Create Order CR\"\n    K8sAPI-&gt;&gt;ARCAPI: \"Forward to arc.bwi.de\"\n    ARCAPI-&gt;&gt;etcd: \"Store Order\"\n\n    etcd--&gt;&gt;OrderCtrl: \"Watch notification\"\n    OrderCtrl-&gt;&gt;OrderCtrl: \"Reconcile()\"\n    OrderCtrl-&gt;&gt;ARCAPI: \"Create Fragment CRs\"\n    ARCAPI-&gt;&gt;etcd: \"Store Fragments\"\n\n    OrderCtrl-&gt;&gt;ARCAPI: \"Get ArtifactTypeDefinition\"\n    ARCAPI--&gt;&gt;OrderCtrl: \"ATD with workflowTemplateRef\"\n\n    OrderCtrl-&gt;&gt;K8sAPI: \"Create Workflow CR\"\n    K8sAPI--&gt;&gt;ArgoCtrl: \"Workflow created\"\n\n    ArgoCtrl-&gt;&gt;Workflow: \"Start workflow pods\"\n    Workflow-&gt;&gt;ARCAPI: \"Read Endpoint configs\"\n    ARCAPI--&gt;&gt;Workflow: \"Endpoint details + secrets\"\n\n    Workflow-&gt;&gt;Registry: \"Pull artifact\"\n    Registry--&gt;&gt;Workflow: \"Artifact data\"\n\n    Workflow-&gt;&gt;Workflow: \"Security scan\"\n    Workflow-&gt;&gt;Registry: \"Push to destination\"\n\n    Workflow--&gt;&gt;ArgoCtrl: \"Workflow complete\"\n    ArgoCtrl-&gt;&gt;K8sAPI: \"Update Workflow status\"\n\n    OrderCtrl-&gt;&gt;ARCAPI: \"Update Order status\"\n    ARCAPI-&gt;&gt;etcd: \"Store status update\"</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#getting-started","title":"Getting started","text":"<p>Users interact with ARC primarily through the <code>arcctl</code> CLI tool, which provides commands for artifact operations and resource management. The CLI communicates with the Kubernetes API Server, which forwards ARC-specific requests to the ARC API Server extension. This creates a declarative workflow where users define desired artifact states, and the system executes the necessary operations.</p>"},{"location":"developer-guide/contributing/","title":"Artifact Conduit (ARC) Developer Guide","text":""},{"location":"developer-guide/contributing/#artifact-conduit-arc-developer-guide","title":"Artifact Conduit (ARC) Developer Guide","text":"<p>This guide provides technical information for developers contributing to the Artifact Conduit (ARC) project. It covers the development workflow, build system, code organization, and common development tasks. For detailed information about specific topics, see the referenced sections.</p>"},{"location":"developer-guide/contributing/#development-workflow-overview","title":"Development Workflow Overview","text":"<p>ARC follows a code-generation-heavy pattern typical in Kubernetes ecosystem projects. Changes to API types trigger code regeneration, which produces client libraries, OpenAPI specifications, and CRD manifests.</p>"},{"location":"developer-guide/contributing/#build-system","title":"Build System","text":"<p>The ARC build system uses a Makefile to orchestrate various tools, designed for reproducibility. All required tools are provided in the <code>bin/</code> directory.</p> Target Purpose Key Tools Used <code>make codegen</code> Generate client-go libraries &amp; OpenAPI <code>openapi-gen</code>, <code>kube_codegen.sh</code> <code>make manifests</code> Generate CRDs and RBAC manifests <code>controller-gen</code> <code>make fmt</code> Format code, add license headers <code>addlicense</code>, <code>go fmt</code> <code>make lint</code> Run linters and checks <code>golangci-lint</code>, <code>shellcheck</code>, <code>addlicense</code> <code>make test</code> Run all tests with coverage <code>ginkgo</code>, <code>setup-envtest</code> <code>make clean</code> Remove generated binaries -"},{"location":"developer-guide/contributing/#tool-versions","title":"Tool Versions","text":"<p>The system pins specific tool versions for reproducibility:</p> <ul> <li>BDD testing framework: <code>v2.27.2</code></li> <li>Go linter: <code>v2.5.0</code></li> <li>CRD/RBAC generator: <code>v0.19.0</code></li> <li>Kubernetes test API server: <code>release-0.22</code></li> <li>K8s for integration tests: <code>1.34.1</code></li> </ul>"},{"location":"developer-guide/contributing/#codebase-organization","title":"Codebase Organization","text":"<p>ARC codebase follows standard Kubernetes project conventions:</p> Directory Purpose Generated/Manual <code>api/arc/v1alpha1/</code> Custom resource type definitions Manual <code>client-go/</code> Client libraries for ARC resources Generated <code>pkg/apiserver/</code> Extension API server implementation Manual <code>pkg/controller/</code> Controller reconciliation logic Manual <code>pkg/registry/</code> Storage strategies for custom resources Manual <code>cmd/arcctl/</code> CLI tool implementation Manual <code>config/</code> Kubernetes manifests (CRDs, RBAC) Generated <code>hack/</code> Build and code generation scripts Manual"},{"location":"developer-guide/contributing/#code-generation-process","title":"Code Generation Process","text":"<p>ARC uses the Kubernetes code-generator to produce client libraries and OpenAPI specs.</p> <ul> <li><code>make codegen</code> triggers <code>hack/update-codegen.sh</code></li> <li>Generates:</li> <li>Client-go libraries in <code>client-go/</code></li> <li>OpenAPI specs</li> <li>CRD manifests</li> </ul> <p>See Client Libraries section for usage details.</p>"},{"location":"developer-guide/contributing/#testing-strategy","title":"Testing Strategy","text":"<p>ARC uses a multi-layered testing strategy:</p> <ul> <li>Unit Tests</li> <li>Integration Tests (uses <code>ENVTEST_K8S_VERSION=1.34.1</code>)</li> <li>Controller Tests via envtest</li> </ul> <p>Run all tests and generate coverage:</p> <pre><code>make test\n</code></pre> <p>Setup environment for integration tests:</p> <pre><code>setup-envtest\nexport ENVTEST_K8S_VERSION=1.34.1\n</code></pre> <p>Test coverage is tracked using Coveralls.</p>"},{"location":"developer-guide/contributing/#continuous-integration-ci-pipeline","title":"Continuous Integration (CI) Pipeline","text":"<p>Pipeline runs on every push and pull request, enforcing code quality and test coverage.</p> <ul> <li>Lint Job</li> <li><code>addlicense</code></li> <li><code>shellcheck</code></li> <li><code>golangci-lint</code></li> <li>Test Job (runs after Lint)</li> <li><code>make test</code></li> </ul> <p>For customization details, see <code>.github/workflows/golang.yaml</code>.</p>"},{"location":"developer-guide/contributing/#adding-a-new-custom-resource","title":"Adding a New Custom Resource","text":"<p>To introduce a new CRD:</p> <ol> <li>Create type definition in <code>api/arc/v1alpha1/</code></li> <li>Add OpenAPI model name</li> <li>Regenerate code via <code>make codegen</code></li> <li>Implement storage in <code>pkg/registry/</code></li> <li>Add controller logic in <code>pkg/controller/</code> if reconciliation is needed</li> </ol> <p>See <code>hack/update-codegen.sh</code> for implementation details.</p>"},{"location":"developer-guide/contributing/#modifying-existing-api-types","title":"Modifying Existing API Types","text":"<p>Typical steps:</p> <ol> <li>Edit types in <code>api/arc/v1alpha1/</code></li> <li>Run <code>make codegen</code></li> <li>Run <code>make manifests</code></li> <li>Run <code>make test</code></li> </ol> <p>Note: Breaking changes may affect existing clients. Follow semantic versioning and provide migration paths.</p>"},{"location":"developer-guide/contributing/#code-quality-linting","title":"Code Quality &amp; Linting","text":"<p>Lint and license checks before committing:</p> <ul> <li><code>addlicense</code> for Apache 2.0 headers</li> <li><code>shellcheck</code> for scripts in <code>hack/</code></li> <li><code>golangci-lint</code> for Go linting</li> </ul> <p>Fix issues with:</p> <pre><code>make fmt\nmake lint\n</code></pre>"},{"location":"developer-guide/dod/","title":"Definition of Done","text":""},{"location":"developer-guide/dod/#definition-of-done","title":"Definition of Done","text":"<p>TODO</p>"},{"location":"developer-guide/working-with-docs/","title":"Documentation Setup","text":""},{"location":"developer-guide/working-with-docs/#documentation-setup","title":"Documentation Setup","text":"<p>The documentation of the ARC project is written primarily using Markdown. All documentation related content can be found in https://github.com/opendefensecloud/artifact-conduit/tree/main/docs. New content also should be added there.</p> <p>To render the documentation with <code>mkdocs</code> locally use <code>make docs</code> and open the local page:</p> <pre><code>$ make docs\nmkdocs serve\nINFO    -  Building documentation...\nINFO    -  Cleaning site directory\nINFO    -  Documentation built in 0.22 seconds\nINFO    -  [13:29:25] Watching paths for changes: 'docs', 'mkdocs.yml'\nINFO    -  [13:29:25] Serving on http://127.0.0.1:8000/\n</code></pre>"},{"location":"developer-guide/adrs/000-Use-Markdown-Architectural-Decision-Records/","title":"Find a Common Way to Document Architectural Design Decsisions","text":""},{"location":"developer-guide/adrs/000-Use-Markdown-Architectural-Decision-Records/#find-a-common-way-to-document-architectural-design-decsisions","title":"Find a Common Way to Document Architectural Design Decsisions","text":""},{"location":"developer-guide/adrs/000-Use-Markdown-Architectural-Decision-Records/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>We want to record architectural decisions made in this project independent whether decisions concern the architecture (\"architectural decision record\"), the code, or other fields. Which format and structure should these records follow?</p>"},{"location":"developer-guide/adrs/000-Use-Markdown-Architectural-Decision-Records/#considered-options","title":"Considered Options","text":"<ul> <li>MADR\u00a04.0.0 \u2013 The Markdown Architectural Decision Records</li> <li>Michael Nygard's template\u00a0\u2013 The first incarnation of the term \"ADR\"</li> <li>Sustainable Architectural Decisions\u00a0\u2013 The Y-Statements</li> <li>Other templates listed at\u00a0https://github.com/joelparkerhenderson/architecture_decision_record</li> <li>Formless \u2013 No conventions for file format and structure</li> </ul>"},{"location":"developer-guide/adrs/000-Use-Markdown-Architectural-Decision-Records/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"MADR 4.0.0\", because</p> <ul> <li>Implicit assumptions should be made explicit. Design documentation is important to enable people understanding the decisions later on. See also\u00a0\"A rational design process: How and why to fake it\".</li> <li>MADR allows for structured capturing of any decision.</li> <li>The MADR format is lean and fits our development style.</li> <li>The MADR structure is comprehensible and facilitates usage &amp; maintenance.</li> <li>The MADR project is vivid.</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/","title":"Evaluate Future ARC Architecture Based on Predecessors","text":""},{"location":"developer-guide/adrs/001-ARC-Architecture/#evaluate-future-arc-architecture-based-on-predecessors","title":"Evaluate Future ARC Architecture Based on Predecessors","text":""},{"location":"developer-guide/adrs/001-ARC-Architecture/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>This ADR is about finding the right architecture for the ARC suite of services based on the knowledge gained during the internal predecessors of this project.</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#glossary","title":"Glossary","text":"<ul> <li><code>arcctl</code>: Command line utility to interact with the ARC API.</li> <li><code>Order</code>: Represents an order of one or more artifacts. Even ordering artifacts that may exist in the future can be reference here using semver expressions for example.</li> <li><code>OrderFragment</code>: Represents a single artifact order which is part of an <code>Order</code>.</li> <li><code>OrderTypeDefinition</code>: Defines rules and defaults for a specific order type like 'OCI'. References a certain workflow to use for that type.</li> <li><code>Endpoint</code>: General term for source or destination. Can be a source or destination for artifacts. Includes optional credentials to access it.</li> <li><code>WorkflowTemplate</code>: Argo Workflows, see https://argo-workflows.readthedocs.io/en/latest/fields/#workflowtemplate</li> <li><code>Workflow</code>: Argo Workflows, see https://argo-workflows.readthedocs.io/en/latest/fields/#workflow</li> <li><code>ARC API Server</code>: A Kubernetes Extension API Server which handles storage of ARC API</li> <li><code>Order Controller</code>: A Kubernetes Controller which reconciles <code>Orders</code>, splits up <code>Order</code> resources into <code>OrderFragment</code> Resources, creates <code>Workflow</code> resources for necessary workload</li> <li><code>ArtifactTypeDefinition</code>: Specifies the processing rules and workflow templates for artifact types (e.g. <code>oci</code>, <code>helm</code>).</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#considered-options","title":"Considered Options","text":""},{"location":"developer-guide/adrs/001-ARC-Architecture/#classic-kubernetes-operators","title":"Classic Kubernetes Operators","text":"<ul> <li>CRDs are used to interact with ARC via the Kubernetes API Server.</li> <li>Several operators come into play which reconcile the different custom resources.</li> <li>A sharding mechanism is implemented to be able to scale the workers horizontally and give every worker a given chunk of resources to reconcile.</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#pros","title":"Pros","text":"<ul> <li>CRDs and Kubernetes are relatively simple to implement</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#cons","title":"Cons","text":"<ul> <li>Storage may be limited by <code>etcd</code> and can bring the control plane of Kubernetes into trouble if too many resources are present</li> <li>The necessity to implement sharding may be hard work and error prone</li> <li>Thus said it may not scale in way necessary for such a solution</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#extension-api-server-and-cncf-landscape-tooling","title":"Extension API Server and CNCF Landscape Tooling","text":""},{"location":"developer-guide/adrs/001-ARC-Architecture/#flavor-a","title":"Flavor A","text":"<p>Flavor uses several controllers to handle different parts of the API. Orders are reconciled and converted to hydrated Orders which contain the source and destination information along with the artifact to process. This information are published to some message queue which is subscribed by workers working on that queue. Optionally KEDA is used to scale, handle quotas and fairness. The database to be used for the API Server is etcd.</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#flavor-b","title":"Flavor B","text":"<p>Same as Flavor A except the database for the API Server is something like Postgres instead of etcd. Additionally the option is considered to let the controller access the Postgres directly to reconcile without using the Kubernetes API Server.</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#flavor-c","title":"Flavor C","text":"<p>Same as Flavor B except that no message queue is used but the job queue is stored directly in the Postgres database.</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#flavor-d","title":"Flavor D","text":"<p>Same as Flavor A except that no message queue is used. The Order controller creates hydrated orders directly in <code>etcd</code> as readonly resource which is then consumed by workers directly. This approach needs some kind of sharding mechanism to have the workers to know which shard of resources they need to handle.</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#flavor-e","title":"Flavor E","text":"<p>This flavor is the most compelling due to the reduced amount of code that is necessary to bring this solution to live. etcd is used as storage for the API server. Argo Workflows is used to build workflows which do the steps necessary to process one artifact. Kueue can be used to bring fairness, scaling, quotas into play which workflows. The order controller creates \"jobs\" which are actually Argo Workflows.</p> <p>This option is described in detail in the following document.</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#technology","title":"Technology","text":"<ul> <li>Instead of CRDs, <code>ARC</code> uses an Extension API Server via the Kubernetes API Aggregation Layer to handle API requests.</li> <li>This gives it the possibility to use a dedicated <code>etcd</code> or a even more suitable storage backend for the high amount of resources and status information in case this is necessary.</li> <li>While <code>etcd</code> still can be used as storage backend, it is one separated from the <code>etcd</code> used by the Kubernetes control plane and reduces the risk of bringing the whole cluster into trouble.</li> <li>Additional links</li> <li>https://github.com/kubernetes-sigs/apiserver-runtime</li> <li>https://github.com/kubernetes/sample-apiserver/tree/master</li> <li>Utilize Argo Workflows to handle the workflows necessary to process different artifact types</li> <li>Optionally use Kueue to handle quotas and enhanced scheduling</li> <li>Namespaces are used to separate resources in a multi-tenant environment.</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#architecture-diagram","title":"Architecture Diagram","text":"<p>Overview Diagram</p> <p></p> <p>API Concept Diagram</p> <pre><code>---\nconfig:\n  layout: elk\n---\nflowchart LR\n subgraph subGraph0[\"Declarative Layer\"]\n        Order[\"Order (User Input)\"]\n        Spec[\"spec:&lt;br&gt;- defaults&lt;br&gt;- artifacts[]\"]\n  end\n subgraph subGraph1[\"Generated Layer\"]\n        Fragment1[\"Fragment-1\"]\n        Fragment2[\"Fragment-2\"]\n        FragmentN[\"Fragment-N\"]\n  end\n subgraph Configuration[\"Configuration\"]\n        ArtifactTypeDef@{ label: \"ArtifactTypeDefinition (e.g., 'oci')\" }\n        EndpointSrc[\"Endpoint (Source)\"]\n        EndpointDst[\"Endpoint (Destination)\"]\n        Secret[\"Secret (Credentials)\"]\n  end\n subgraph Execution[\"Execution\"]\n        WorkflowTemplate[\"WorkflowTemplate (Argo)\"]\n        WorkflowInstance1[\"Workflow Instance\"]\n        WorkflowInstance2[\"Workflow Instance\"]\n  end\n    Order -- contains --&gt; Spec\n    Spec -- generates --&gt; Fragment1 &amp; Fragment2 &amp; FragmentN\n    Fragment1 -- type --&gt; ArtifactTypeDef\n    Fragment2 -- type --&gt; ArtifactTypeDef\n    Fragment1 -- srcRef --&gt; EndpointSrc\n    Fragment2 -- srcRef --&gt; EndpointSrc\n    Fragment1 -- dstRef --&gt; EndpointDst\n    Fragment2 -- dstRef --&gt; EndpointDst\n    Fragment1 -- references --&gt; EndpointSrc &amp; EndpointDst\n    Fragment2 -- references --&gt; EndpointSrc &amp; EndpointDst\n    EndpointSrc -- credentialRef --&gt; Secret\n    EndpointDst -- credentialRef --&gt; Secret\n    ArtifactTypeDef -- workflowTemplateRef --&gt; WorkflowTemplate\n    Fragment1 -- triggers --&gt; WorkflowTemplate\n    Fragment2 -- triggers --&gt; WorkflowTemplate\n    WorkflowTemplate -- instantiates --&gt; WorkflowInstance1 &amp; WorkflowInstance2\n    ArtifactTypeDef@{ shape: rect}\n</code></pre> <p>The solution shows the ARC API Server which handles storage for the custom resources / API of ARC. <code>etcd</code> is used as storage solution. <code>Order Controller</code> is a classic Kubernetes controller implementation which reconciles <code>Orders</code> and <code>Endpoints</code>. An <code>Order</code> contains the information what artifacts should be processed. An <code>Endpoint</code> contains the information about a source or destination for artifacts. The <code>Order Controller</code> creates <code>Fragment</code> resources which are single artifacts decomposed from an <code>Order</code>. An <code>ArtifactTypeDefinition</code> specifies the processing rules and workflow templates for artifact types (e.g. <code>oci</code>, <code>helm</code>).</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#pros_1","title":"Pros","text":"<ul> <li>Using dedicated <code>etcd</code> does not clutter the infra etcd</li> <li>Storage can be changed later on if necessary</li> <li>Keep the declarative style of Kubernetes while having complete freedom on the API implementation</li> <li>Argo Workflows allows us to focus on the domain of the product without reinventing the wheel</li> <li>Qotas and Fairness easy without writing code via Kueue</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#cons_1","title":"Cons","text":"<ul> <li>Building addon apiservers directly on the raw api-machinery libraries requires non-trivial code that must be maintained and rebased as the raw libraries change.</li> <li>Steep learning curve when starting the project and steeper learning curve when joining the project.</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen Option: Solution A.</p> <p>Because the solution is the one that provides the most flexibility while the necessity to write own code for many parts is minimized. The flexibility comes from utilizing the CNCF projects Argo Workflows and Kueue for building the workflow engine. The project itself can focus on the order process and the handling of endpoints.</p>"},{"location":"developer-guide/adrs/002-ARC-API/","title":"Define an Optimal API for the Project Beginning","text":""},{"location":"developer-guide/adrs/002-ARC-API/#define-an-optimal-api-for-the-project-beginning","title":"Define an Optimal API for the Project Beginning","text":""},{"location":"developer-guide/adrs/002-ARC-API/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>This ADR is about finding the right API for ARC.</p>"},{"location":"developer-guide/adrs/002-ARC-API/#proposed-solution","title":"Proposed Solution","text":"<p>Options were discussed and documented here: https://app.bwi.conceptboard.com/board/u9c0-4nk5-rrhd-knre-6cfn</p> <pre><code>apiVersion: arc.bwi.de/v1alpha1\nkind: Order\nmetadata:\n  name: example-order\nspec:\n  defaults:\n    srcRef:\n      name: docker-hub\n      namespace: default # optional\n    dstRef:\n      name: internal-registry\n  artifacts:\n    - type: oci # artifactType, correcesponds to workflow\n      dstRef:\n        name: other-internal-registry\n        namespace: default # optional\n      spec:\n        image: library/alpine:3.18\n        override: myteam/alpine:3.18-dev # default alpine:3.18; support CEL?\n    - type: oci\n      spec:\n        image: library/ubuntu:1.0\n    - type: helm\n      srcRef:\n        name: jetstack-helm\n      dstRef:\n        name: internal-helm-registry\n      spec:\n        name: cert-manager\n        version: \"47.11\"\n        override: helm-charts/cert-manager:47.11\n</code></pre> <pre><code>apiVersion: arc.bwi.de/v1alpha1\nkind: Fragment\nmetadata:\n  name: example-order-1 # sha256 for procedural\nspec:\n  type: oci # artifactType, correcesponds to workflow\n  srcRef: # required\n    name: lala\n  dstRef: #required\n    name: other-internal-registry\n    namespace: default # optional\n  spec:\n    image: library/alpine:3.18\n    override: myteam/alpine:3.18-dev # default alpine:3.18; support CEL?\n</code></pre> <pre><code>apiVersion: arc.bwi.de/v1alpha1\nkind: Endpoint\nmetadata:\n  name: internal-registry\nspec:\n  type: oci # Endpoint Type! set valid types on controller manager?\n  remoteURL: https://artifactory.example.com/artifactory/ace-oci-local\n  secretRef: # STANDARDIZED!\n    name: internal-registry-credentials\n  usage: PullOnly | PushOnly | All # enum\n</code></pre> <pre><code>apiVersion: arc.bwi.de/v1alpha1\nkind: ArtifactTypeDefinition\nmetadata:\n  name: oci\nspec:\n  rules:\n    srcTypes:\n      - s3 # Endpoint Types!\n      - oci\n      - helm\n    dstTypes:\n      - oci\n  defaults:\n    dstRef: internal-registry\n  workflowTemplateRef: # argo.Workflow\n</code></pre>"},{"location":"operator-manual/installation/","title":"Installation","text":""},{"location":"operator-manual/installation/#installation","title":"Installation","text":"<p>TODO</p>"},{"location":"operator-manual/new-features/","title":"New Features","text":""},{"location":"operator-manual/new-features/#new-features","title":"New Features","text":"<p>TODO</p>"},{"location":"operator-manual/releases/","title":"Releases","text":""},{"location":"operator-manual/releases/#releases","title":"Releases","text":"<p>TODO</p>"},{"location":"operator-manual/security/","title":"Security","text":""},{"location":"operator-manual/security/#security","title":"Security","text":"<p>TODO</p>"},{"location":"operator-manual/upgrading/","title":"Upgrading","text":""},{"location":"operator-manual/upgrading/#upgrading","title":"Upgrading","text":"<p>TODO</p>"},{"location":"user-guide/core-concepts/","title":"Core Concepts","text":""},{"location":"user-guide/core-concepts/#core-concepts","title":"Core Concepts","text":"<p>This document provides a comprehensive overview of the Artifact Conduit (ARC) system architecture, covering its design principles, core components, and how they interact.</p>"},{"location":"user-guide/core-concepts/#purpose-and-scope","title":"Purpose and Scope","text":"<p>ARC is a Kubernetes-native artifact management system designed to securely transport artifacts (OCI images, Helm charts, generic files) across network boundaries, particularly into air-gapped environments. The architecture employs a Kubernetes Extension API Server pattern to provide declarative resource management while maintaining flexibility for future storage backend changes.</p>"},{"location":"user-guide/core-concepts/#architectural-decision","title":"Architectural Decision","text":"<p>ARC's architecture is based on Architectural Decision Record 001, which selected an Extension API Server approach over traditional Custom Resource Definitions (CRDs). This design provides several key advantages:</p> Aspect Decision Rationale API Extension Kubernetes API Aggregation Layer Allows dedicated etcd instance, avoiding cluster control plane pollution Storage Backend Dedicated etcd (replaceable) Enables future migration to alternative storage if needed Workflow Engine Argo Workflows Leverages proven workflow orchestration without reinventing execution logic Declarative Model Kubernetes-style resources Maintains familiar kubectl/GitOps patterns for users <p>The Extension API Server pattern allows ARC to present a Kubernetes-native API surface while maintaining complete control over storage implementation and API behavior.</p>"},{"location":"user-guide/core-concepts/#system-components","title":"System Components","text":""},{"location":"user-guide/core-concepts/#component-overview","title":"Component Overview","text":"<pre><code>graph TB\n    subgraph \"Control Plane\"\n        K8sAPI[\"Kubernetes API Server\"]\n        APIAgg[\"API Aggregation Layer\"]\n    end\n\n    subgraph \"ARC System\"\n        APIServer[\"arc-apiserver&lt;br/&gt;(Extension API Server)\"]\n        etcd[\"Dedicated etcd&lt;br/&gt;(Storage Backend)\"]\n        CtrlMgr[\"arc-controller-manager\"]\n        OrderCtrl[\"OrderReconciler\"]\n    end\n\n    subgraph \"Custom Resources\"\n        Order[\"Order CR\"]\n        Fragment[\"Fragment CR\"]\n        Endpoint[\"Endpoint CR\"]\n        ATD[\"ArtifactTypeDefinition CR\"]\n    end\n\n    subgraph \"Execution Layer\"\n        Argo[\"Argo Workflows\"]\n        WorkflowTemplate[\"WorkflowTemplate\"]\n        Workflow[\"Workflow Instance\"]\n    end\n\n    subgraph \"External Systems\"\n        Registry[\"OCI Registries\"]\n        S3[\"S3 Storage\"]\n        Scanners[\"Security Scanners\"]\n    end\n\n    K8sAPI --&gt; APIAgg\n    APIAgg --&gt; APIServer\n    APIServer --&gt; etcd\n\n    CtrlMgr --&gt; OrderCtrl\n    OrderCtrl --&gt; K8sAPI\n    OrderCtrl --&gt; APIServer\n\n    Order --&gt; OrderCtrl\n    OrderCtrl --&gt; Fragment\n    OrderCtrl --&gt; Argo\n\n    Fragment --&gt; Endpoint\n    Fragment --&gt; ATD\n    ATD --&gt; WorkflowTemplate\n    Argo --&gt; Workflow\n\n    Workflow --&gt; Registry\n    Workflow --&gt; S3\n    Workflow --&gt; Scanners</code></pre>"},{"location":"user-guide/core-concepts/#arc-api-server","title":"ARC API Server","text":"<p>The API Server implements the Kubernetes Extension API Server pattern, registering with the Kubernetes API Aggregation Layer to handle requests for the <code>arc.bwi.de</code> API group.</p> <p>Key Characteristics:</p> Property Value Package <code>pkg/apiserver/</code> API Group <code>arc.bwi.de/v1alpha1</code> Storage Dedicated etcd cluster Registration Via APIService resource <p>The API Server is built using <code>apiserver-runtime</code> and <code>sample-apiserver</code> patterns, providing:</p> <ul> <li>Native Kubernetes authentication and authorization integration</li> <li>OpenAPI schema generation</li> <li>Support for standard Kubernetes API conventions (List, Watch, Get, Create, Update, Delete, Patch)</li> <li>Server-side apply functionality</li> </ul> <p>The test environment bootstraps the API Server programmatically for integration testing:</p> <pre><code>graph LR\n    TestEnv[\"envtest.Environment\"]\n    K8sControlPlane[\"envtest Control Plane\"]\n    APIServerProc[\"arc-apiserver Process\"]\n    APIService[\"APIService Resource\"]\n\n    TestEnv --&gt; K8sControlPlane\n    TestEnv --&gt; APIServerProc\n    APIServerProc --&gt; K8sControlPlane\n    K8sControlPlane --&gt; APIService</code></pre>"},{"location":"user-guide/core-concepts/#controller-manager","title":"Controller Manager","text":"<p>The controller manager binary (<code>arc-controller-manager</code>) hosts the Order controller and other reconciliation loops.</p> <p>Binary Location: cmd/arc-controller-manager/main.go:1-196</p> <p>Configuration:</p> Flag Default Purpose <code>--metrics-bind-address</code> <code>0</code> Metrics endpoint address <code>--health-probe-bind-address</code> <code>:8081</code> Health check endpoint <code>--leader-elect</code> <code>false</code> Enable leader election for HA <code>--metrics-secure</code> <code>true</code> Serve metrics over HTTPS <p>The manager initializes with:</p> <ul> <li>Kubernetes client-go scheme + ARC custom resources (cmd/arc-controller-manager/main.go:37-40)</li> <li>Controller-runtime manager with leader election support (cmd/arc-controller-manager/main.go:150-162)</li> <li>OrderReconciler registration (cmd/arc-controller-manager/main.go:173-178)</li> <li>Health and readiness checks (cmd/arc-controller-manager/main.go:182-189)</li> </ul>"},{"location":"user-guide/core-concepts/#resource-model","title":"Resource Model","text":""},{"location":"user-guide/core-concepts/#resource-hierarchy","title":"Resource Hierarchy","text":"<pre><code>graph TB\n    User[\"User/Operator\"]\n\n    subgraph \"Declarative Layer\"\n        Order[\"Order&lt;br/&gt;apiVersion: arc.bwi.de/v1alpha1&lt;br/&gt;kind: Order\"]\n        OrderSpec[\"spec:&lt;br/&gt;- defaults&lt;br/&gt;- artifacts[]\"]\n        OrderDefaults[\"defaults:&lt;br/&gt;- srcRef&lt;br/&gt;- dstRef\"]\n        OrderArtifacts[\"artifacts:&lt;br/&gt;- type&lt;br/&gt;- spec&lt;br/&gt;- srcRef/dstRef overrides\"]\n    end\n\n    subgraph \"Execution Layer\"\n        Fragment1[\"Fragment&lt;br/&gt;apiVersion: arc.bwi.de/v1alpha1&lt;br/&gt;kind: Fragment\"]\n        Fragment2[\"Fragment\"]\n        FragmentSpec[\"spec:&lt;br/&gt;- type&lt;br/&gt;- srcRef&lt;br/&gt;- dstRef&lt;br/&gt;- spec (type-specific)\"]\n    end\n\n    subgraph \"Configuration Layer\"\n        Endpoint1[\"Endpoint&lt;br/&gt;kind: Endpoint\"]\n        Endpoint2[\"Endpoint\"]\n        EndpointSpec[\"spec:&lt;br/&gt;- type&lt;br/&gt;- remoteURL&lt;br/&gt;- secretRef&lt;br/&gt;- usage\"]\n\n        ATD[\"ArtifactTypeDefinition&lt;br/&gt;kind: ArtifactTypeDefinition\"]\n        ATDSpec[\"spec:&lt;br/&gt;- rules&lt;br/&gt;- workflowTemplateRef\"]\n\n        Secret[\"Secret&lt;br/&gt;(credentials)\"]\n    end\n\n    User --&gt; Order\n    Order --&gt; OrderSpec\n    OrderSpec --&gt; OrderDefaults\n    OrderSpec --&gt; OrderArtifacts\n\n    OrderArtifacts -.generates.-&gt; Fragment1\n    OrderArtifacts -.generates.-&gt; Fragment2\n\n    Fragment1 --&gt; FragmentSpec\n    FragmentSpec --&gt; Endpoint1\n    FragmentSpec --&gt; Endpoint2\n    FragmentSpec --&gt; ATD\n\n    Endpoint1 --&gt; EndpointSpec\n    EndpointSpec --&gt; Secret\n    ATD --&gt; ATDSpec</code></pre>"},{"location":"user-guide/core-concepts/#resource-definitions","title":"Resource Definitions","text":""},{"location":"user-guide/core-concepts/#order","title":"Order","text":"<p>High-level declarative resource specifying one or more artifacts to process.</p> <p>API Structure:</p> <ul> <li>Group: <code>arc.bwi.de</code></li> <li>Version: <code>v1alpha1</code></li> <li>Kind: <code>Order</code></li> <li>Spec Fields:</li> <li><code>defaults</code>: Default source and destination endpoints</li> <li><code>artifacts</code>: Array of artifact specifications</li> </ul>"},{"location":"user-guide/core-concepts/#fragment","title":"Fragment","text":"<p>Represents a single artifact operation, generated from Order resources by the Order controller.</p> <p>Generation Logic: The OrderReconciler decomposes an Order into individual Fragments, applying defaults from the Order spec to each Fragment that doesn't specify its own <code>srcRef</code> or <code>dstRef</code>.</p>"},{"location":"user-guide/core-concepts/#endpoint","title":"Endpoint","text":"<p>Defines connection details for artifact sources and destinations.</p> <p>Spec Fields:</p> <ul> <li><code>type</code>: Endpoint type (e.g., <code>oci</code>, <code>s3</code>, <code>helm</code>)</li> <li><code>remoteURL</code>: Connection URL</li> <li><code>secretRef</code>: Reference to Secret containing credentials</li> <li><code>usage</code>: Enum (<code>PullOnly</code>, <code>PushOnly</code>, <code>All</code>)</li> </ul>"},{"location":"user-guide/core-concepts/#artifacttypedefinition","title":"ArtifactTypeDefinition","text":"<p>Defines processing rules and workflow templates for specific artifact types.</p> <p>Spec Fields:</p> <ul> <li><code>rules</code>: Validation rules for source and destination endpoint types</li> <li><code>defaults</code>: Default endpoint references</li> <li><code>workflowTemplateRef</code>: Reference to Argo WorkflowTemplate</li> </ul>"},{"location":"user-guide/core-concepts/#controller-architecture","title":"Controller Architecture","text":""},{"location":"user-guide/core-concepts/#order-reconciliation-flow","title":"Order Reconciliation Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant K8sAPI as \"Kubernetes API\"\n    participant ARCAPI as \"ARC API Server\"\n    participant OrderReconciler as \"OrderReconciler&lt;br/&gt;(pkg/controller)\"\n    participant etcd as \"etcd Storage\"\n    participant Argo as \"Argo Workflows\"\n\n    User-&gt;&gt;K8sAPI: Create Order resource\n    K8sAPI-&gt;&gt;ARCAPI: Forward arc.bwi.de request\n    ARCAPI-&gt;&gt;etcd: Store Order\n\n    Note over OrderReconciler: Watch loop detects change\n\n    etcd--&gt;&gt;OrderReconciler: Order event\n    OrderReconciler-&gt;&gt;OrderReconciler: Reconcile()\n\n    OrderReconciler-&gt;&gt;ARCAPI: List existing Fragments for Order\n    ARCAPI--&gt;&gt;OrderReconciler: Fragment list\n\n    OrderReconciler-&gt;&gt;OrderReconciler: Calculate desired Fragments&lt;br/&gt;from Order.spec.artifacts\n\n    OrderReconciler-&gt;&gt;ARCAPI: Create/Update Fragments\n    ARCAPI-&gt;&gt;etcd: Store Fragments\n\n    OrderReconciler-&gt;&gt;ARCAPI: Get ArtifactTypeDefinition\n    ARCAPI--&gt;&gt;OrderReconciler: ATD with workflowTemplateRef\n\n    OrderReconciler-&gt;&gt;K8sAPI: Create Workflow (via Argo API)\n    K8sAPI-&gt;&gt;Argo: Workflow created\n\n    Argo-&gt;&gt;Argo: Execute workflow\n\n    Argo-&gt;&gt;K8sAPI: Update Workflow status\n    K8sAPI--&gt;&gt;OrderReconciler: Status change event\n\n    OrderReconciler-&gt;&gt;ARCAPI: Update Order status\n    ARCAPI-&gt;&gt;etcd: Store updated status</code></pre> <p>The OrderReconciler implements the controller-runtime <code>Reconciler</code> interface and is registered in the controller manager.</p> <p>Reconciliation Logic:</p> <ol> <li>Fetch Order resource</li> <li>Generate Fragment specifications from <code>Order.spec.artifacts</code></li> <li>Apply defaults from <code>Order.spec.defaults</code> to Fragments</li> <li>Create/update Fragment resources via ARC API Server</li> <li>Lookup ArtifactTypeDefinition for each Fragment type</li> <li>Create Argo Workflow instances using WorkflowTemplate from ATD</li> <li>Update Order status based on Fragment and Workflow states</li> </ol>"},{"location":"user-guide/core-concepts/#storage-architecture","title":"Storage Architecture","text":""},{"location":"user-guide/core-concepts/#dedicated-etcd-instance","title":"Dedicated etcd Instance","text":"<p>Unlike CRD-based solutions that share the cluster's etcd, ARC uses a dedicated etcd cluster. This architectural choice provides:</p> Benefit Description Isolation ARC resource storage doesn't impact cluster control plane Scalability Independent scaling for high artifact throughput Flexibility Storage backend can be replaced without API changes Performance Optimized storage parameters for ARC's access patterns <p>The API Server connects to etcd using standard etcd v3 client configuration. In the test environment, this is provided by envtest's embedded etcd:</p> <p>pkg/envtest/environment.go:56 - The API Server is configured with etcd servers from the test environment's control plane.</p>"},{"location":"user-guide/core-concepts/#workflow-integration","title":"Workflow Integration","text":""},{"location":"user-guide/core-concepts/#argo-workflows-execution-model","title":"Argo Workflows Execution Model","text":"<p>ARC delegates actual artifact processing to Argo Workflows, which provides:</p> <ul> <li>DAG-based workflow execution</li> <li>Container-native artifact handling</li> <li>Retry and failure handling</li> <li>Status reporting</li> </ul> <pre><code>graph TB\n    subgraph \"ARC Resources\"\n        Fragment[\"Fragment\"]\n        ATD[\"ArtifactTypeDefinition\"]\n        Endpoint1[\"Endpoint (source)\"]\n        Endpoint2[\"Endpoint (destination)\"]\n    end\n\n    subgraph \"Argo Resources\"\n        WorkflowTemplate[\"WorkflowTemplate&lt;br/&gt;(defines steps)\"]\n        Workflow[\"Workflow&lt;br/&gt;(execution instance)\"]\n    end\n\n    subgraph \"Workflow Steps\"\n        PullStep[\"Pull Artifact&lt;br/&gt;(from srcRef)\"]\n        ScanStep[\"Security Scan&lt;br/&gt;(Trivy, ClamAV)\"]\n        ValidateStep[\"Validate&lt;br/&gt;(signatures, policies)\"]\n        PushStep[\"Push Artifact&lt;br/&gt;(to dstRef)\"]\n    end\n\n    Fragment --&gt; ATD\n    ATD --&gt; WorkflowTemplate\n    Fragment --&gt; Workflow\n    WorkflowTemplate --&gt; Workflow\n\n    Fragment --&gt; Endpoint1\n    Fragment --&gt; Endpoint2\n\n    Workflow --&gt; PullStep\n    PullStep --&gt; ScanStep\n    ScanStep --&gt; ValidateStep\n    ValidateStep --&gt; PushStep\n\n    Endpoint1 -.credentials.-&gt; PullStep\n    Endpoint2 -.credentials.-&gt; PushStep</code></pre> <p>Workflow Creation: The OrderReconciler creates Workflow instances by:</p> <ol> <li>Reading the <code>workflowTemplateRef</code> from the ArtifactTypeDefinition</li> <li>Instantiating a Workflow from the template</li> <li>Passing Fragment metadata and Endpoint references as workflow parameters</li> <li>Submitting the Workflow to Argo via Kubernetes API</li> </ol> <p>Status Propagation: Workflow status changes are watched by the OrderReconciler and propagated to Fragment and Order status fields.</p>"},{"location":"user-guide/core-concepts/#testing-infrastructure","title":"Testing Infrastructure","text":""},{"location":"user-guide/core-concepts/#test-environment-architecture","title":"Test Environment Architecture","text":"<pre><code>graph TB\n    subgraph \"Test Suite\"\n        TestCode[\"Integration Tests&lt;br/&gt;(Ginkgo)\"]\n    end\n\n    subgraph \"envtest.Environment\"\n        EnvtestCtrl[\"envtest Control Plane&lt;br/&gt;(API Server + etcd)\"]\n        EnvtestEtcd[\"envtest etcd\"]\n\n        APIServerProc[\"arc-apiserver Process&lt;br/&gt;(started via buildutils)\"]\n\n        APIService[\"APIService Resource&lt;br/&gt;(registers arc.bwi.de)\"]\n    end\n\n    subgraph \"Test Resources\"\n        TestNS[\"Test Namespace\"]\n        TestOrder[\"Test Order\"]\n        TestFragment[\"Test Fragment\"]\n    end\n\n    TestCode --&gt; EnvtestCtrl\n    TestCode --&gt; APIServerProc\n\n    EnvtestCtrl --&gt; EnvtestEtcd\n    EnvtestCtrl --&gt; APIService\n\n    APIServerProc --&gt; EnvtestEtcd\n    APIService --&gt; APIServerProc\n\n    TestCode --&gt; TestNS\n    TestCode --&gt; TestOrder\n    TestCode --&gt; TestFragment\n\n    TestOrder -.stored in.-&gt; EnvtestEtcd\n    TestFragment -.stored in.-&gt; EnvtestEtcd</code></pre> <p>The test environment (<code>pkg/envtest/environment.go</code>) provides a complete ARC deployment for integration testing:</p> <p>Initialization: pkg/envtest/environment.go:30-40</p> <ul> <li>Creates envtest Kubernetes environment with APIService definitions</li> <li>Starts arc-apiserver binary via buildutils</li> <li>Configures API Server to use envtest etcd</li> <li>Waits for APIService readiness</li> </ul> <p>Test Setup: pkg/apiserver/suite_test.go:67-83</p> <ul> <li>Creates isolated test namespaces per test case</li> <li>Provides Kubernetes client configured for ARC resources</li> <li>Automatic cleanup on test completion</li> </ul> <p>Sources: pkg/envtest/environment.go:1-93, pkg/apiserver/suite_test.go:1-84</p>"},{"location":"user-guide/core-concepts/#component-interactions","title":"Component Interactions","text":""},{"location":"user-guide/core-concepts/#request-flow-for-artifact-processing","title":"Request Flow for Artifact Processing","text":"<pre><code>sequenceDiagram\n    participant CLI as \"arcctl CLI\"\n    participant K8sAPI as \"Kubernetes API\"\n    participant APIAgg as \"API Aggregation\"\n    participant ARCAPI as \"arc-apiserver\"\n    participant etcd as \"Dedicated etcd\"\n    participant Ctrl as \"OrderReconciler\"\n    participant Argo as \"Argo Controller\"\n    participant Worker as \"Workflow Pod\"\n    participant Registry as \"OCI Registry\"\n\n    CLI-&gt;&gt;K8sAPI: POST /apis/arc.bwi.de/v1alpha1/orders\n    K8sAPI-&gt;&gt;APIAgg: Route to arc.bwi.de\n    APIAgg-&gt;&gt;ARCAPI: Forward request\n    ARCAPI-&gt;&gt;etcd: Write Order\n    etcd--&gt;&gt;ARCAPI: Success\n    ARCAPI--&gt;&gt;CLI: Order created\n\n    Note over Ctrl: Watch event received\n\n    Ctrl-&gt;&gt;ARCAPI: GET Order\n    ARCAPI-&gt;&gt;etcd: Read Order\n    etcd--&gt;&gt;ARCAPI: Order data\n    ARCAPI--&gt;&gt;Ctrl: Order object\n\n    Ctrl-&gt;&gt;Ctrl: Generate Fragments\n\n    Ctrl-&gt;&gt;ARCAPI: POST Fragments\n    ARCAPI-&gt;&gt;etcd: Write Fragments\n\n    Ctrl-&gt;&gt;ARCAPI: GET ArtifactTypeDefinition\n    ARCAPI-&gt;&gt;etcd: Read ATD\n    etcd--&gt;&gt;ARCAPI: ATD with workflowTemplateRef\n    ARCAPI--&gt;&gt;Ctrl: ATD object\n\n    Ctrl-&gt;&gt;K8sAPI: POST Workflow\n    K8sAPI-&gt;&gt;Argo: Workflow created\n\n    Argo-&gt;&gt;K8sAPI: Create Workflow Pod\n    K8sAPI-&gt;&gt;Worker: Start Pod\n\n    Worker-&gt;&gt;ARCAPI: GET Endpoints\n    ARCAPI-&gt;&gt;etcd: Read Endpoints\n    etcd--&gt;&gt;ARCAPI: Endpoint configs\n    ARCAPI--&gt;&gt;Worker: Endpoint data\n\n    Worker-&gt;&gt;Registry: Pull artifact (source)\n    Registry--&gt;&gt;Worker: Artifact data\n\n    Worker-&gt;&gt;Worker: Security scan\n\n    Worker-&gt;&gt;Registry: Push artifact (destination)\n    Registry--&gt;&gt;Worker: Success\n\n    Worker-&gt;&gt;K8sAPI: Update Workflow status\n    K8sAPI--&gt;&gt;Ctrl: Status event\n\n    Ctrl-&gt;&gt;ARCAPI: PATCH Order status\n    ARCAPI-&gt;&gt;etcd: Update Order status</code></pre> <p>This sequence shows the complete lifecycle from user command to artifact delivery, highlighting the separation between declarative resource management (ARC API Server) and execution (Argo Workflows).</p>"},{"location":"user-guide/core-concepts/#design-principles","title":"Design Principles","text":""},{"location":"user-guide/core-concepts/#separation-of-concerns","title":"Separation of Concerns","text":"Layer Responsibility Implementation API Layer Resource CRUD, validation, storage arc-apiserver + etcd Control Layer Reconciliation, Fragment generation OrderReconciler Execution Layer Artifact processing, scanning Argo Workflows Configuration Layer Endpoint definitions, type rules Endpoint, ATD resources"},{"location":"user-guide/core-concepts/#declarative-vs-imperative","title":"Declarative vs. Imperative","text":"<p>ARC follows Kubernetes conventions:</p> <ul> <li>Declarative: Users create Order resources describing desired artifacts</li> <li>Reconciliation: Controllers continuously reconcile actual state toward desired state</li> <li>Status Reporting: Status fields reflect current state and progress</li> </ul>"},{"location":"user-guide/core-concepts/#extension-api-server-benefits","title":"Extension API Server Benefits","text":"<p>The Extension API Server pattern provides:</p> <ol> <li>Future-Proof Storage: etcd can be replaced with alternative storage without changing the API</li> <li>Performance Isolation: High-volume artifact operations don't impact cluster control plane</li> <li>Custom Behavior: Full control over API semantics, validation, and storage strategies</li> <li>Standard Tooling: Compatible with kubectl, client-go, and GitOps tools</li> </ol> <p>Trade-offs:</p> <ul> <li>More complex deployment (requires APIService registration)</li> <li>Steeper learning curve for contributors</li> <li>Additional operational considerations (etcd management)</li> </ul>"},{"location":"user-guide/core-concepts/#summary","title":"Summary","text":"<p>ARC's architecture achieves Kubernetes-native artifact management through:</p> <ol> <li>Extension API Server: Provides declarative resource model with flexible storage backend</li> <li>Controller Pattern: OrderReconciler decomposes high-level Orders into executable Fragments</li> <li>Argo Integration: Leverages proven workflow engine for artifact processing</li> <li>Dedicated Storage: Isolated etcd prevents impact on cluster control plane</li> <li>Resource Model: Clean separation between configuration (Endpoint, ATD) and operations (Order, Fragment)</li> </ol>"},{"location":"user-guide/custom-resources/order/","title":"Order Resource","text":""},{"location":"user-guide/custom-resources/order/#order-resource","title":"Order Resource","text":"<p>The <code>Order</code> resource is the primary user-facing interface for requesting artifact operations. It allows users to declare multiple artifacts with shared default configurations.</p>"},{"location":"user-guide/custom-resources/order/#structure","title":"Structure","text":"<pre><code>apiVersion: arc.bwi.de/v1alpha1\nkind: Order\nmetadata:\n  name: example-order\n  namespace: default\nspec:\n  defaults:\n    srcRef:\n      name: docker-hub\n    dstRef:\n      name: internal-registry\n  artifacts:\n    - type: oci\n      spec:\n        image: library/alpine:3.18\n    - type: oci\n      dstRef:\n        name: other-registry\n      spec:\n        image: library/ubuntu:1.0\nstatus:\n  fragments:\n    \"abc123\": {name: \"example-order-abc123\"}\n    \"def456\": {name: \"example-order-def456\"}\n</code></pre>"}]}