{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#what-is-artifact-conduit-arc","title":"What is Artifact Conduit (ARC)?","text":"<p>ARC (Artifact Conduit) is an open-source system that acts as a gateway for procuring various artifact types and transferring them across security zones while ensuring policy compliance through automated scanning and validation. The system addresses the challenge of bringing external artifacts\u2014container images, Helm charts, software packages, and other resources\u2014into restricted environments where direct internet access is prohibited.</p> <p>Primary Goals:</p> <ul> <li>Artifact Procurement: Pull artifacts from diverse sources including OCI registries, Helm repositories, S3-compatible storage, and HTTP endpoints</li> <li>Security Validation: Perform malware scanning, CVE analysis, license verification, and signature validation before artifact transfer</li> <li>Policy Enforcement: Ensure only artifacts meeting defined security and compliance policies cross security boundaries</li> <li>Declarative Management: Leverage Kubernetes-native declarative configuration for artifact lifecycle management</li> <li>Auditability: Provide attestation and traceability of all artifact processing operations</li> </ul> <p>Out of Scope: ARC does not replace existing registry solutions or artifact repositories. It functions as an orchestration layer that coordinates artifact transfer and validation between existing infrastructure components.</p>"},{"location":"#system-architecture","title":"System Architecture","text":"<p>ARC is implemented as a Kubernetes Extension API Server integrated with the Kubernetes API Aggregation Layer. This architectural approach provides several advantages over Custom Resource Definitions (CRDs), including dedicated storage isolation, custom API implementation flexibility, and reduced risk to the hosting cluster's control plane.</p> graph TB     subgraph \"User Layer\"         Users[\"Users/Operators\"]         arcctl[\"arcctl CLI&lt;br/&gt;cmd/arcctl/main.go\"]     end      subgraph \"Kubernetes Control Plane\"         K8sAPI[\"Kubernetes API Server&lt;br/&gt;API Aggregation Layer\"]     end      subgraph \"ARC Control Plane\"         ARCAPI[\"ARC API Server&lt;br/&gt;pkg/apiserver/&lt;br/&gt;Extension API Server\"]         etcdStore[\"Dedicated etcd&lt;br/&gt;Isolated Storage\"]         OrderCtrl[\"Order Controller&lt;br/&gt;pkg/controller/&lt;br/&gt;Reconciliation Logic\"]     end      subgraph \"API Resources (api/arc.bwi.de/v1alpha1)\"         Order[\"Order&lt;br/&gt;High-level request\"]         Fragment[\"Fragment&lt;br/&gt;Single artifact op\"]         Endpoint[\"Endpoint&lt;br/&gt;Source/Destination\"]         ATD[\"ArtifactTypeDefinition&lt;br/&gt;Type rules\"]     end      subgraph \"Execution Layer\"         ArgoWorkflows[\"Argo Workflows&lt;br/&gt;Workflow Execution\"]         WorkflowTemplates[\"WorkflowTemplate&lt;br/&gt;Processing Logic\"]     end      subgraph \"External Systems\"         OCIReg[\"OCI Registries\"]         HelmRepo[\"Helm Repositories\"]         S3Storage[\"S3 Compatible Storage\"]         Scanners[\"Security Scanners&lt;br/&gt;Trivy, ClamAV\"]     end      Users --&gt;|\"CLI commands\"| arcctl     arcctl --&gt;|\"API requests\"| K8sAPI      K8sAPI --&gt;|\"forwards arc.bwi.de/*\"| ARCAPI     ARCAPI --&gt;|\"stores/retrieves\"| etcdStore      OrderCtrl --&gt;|\"watches\"| etcdStore     OrderCtrl --&gt;|\"creates\"| Fragment     OrderCtrl --&gt;|\"creates\"| ArgoWorkflows      Order --&gt;|\"references\"| Endpoint     Order --&gt;|\"uses\"| ATD     Fragment --&gt;|\"references\"| Endpoint      ATD --&gt;|\"specifies\"| WorkflowTemplates     ArgoWorkflows --&gt;|\"instantiates\"| WorkflowTemplates      ArgoWorkflows --&gt;|\"pulls from\"| OCIReg     ArgoWorkflows --&gt;|\"pulls from\"| HelmRepo     ArgoWorkflows --&gt;|\"pulls from\"| S3Storage     ArgoWorkflows --&gt;|\"scans with\"| Scanners     ArgoWorkflows --&gt;|\"pushes to\"| OCIReg <p>Architecture: ARC System Components and Data Flow</p> <p>The system follows a layered architecture where users interact through the <code>arcctl</code> CLI tool, requests flow through the Kubernetes API aggregation layer to the ARC API Server, and the Order Controller orchestrates workflow execution by decomposing high-level Orders into executable Fragments.</p>"},{"location":"#core-concepts","title":"Core Concepts","text":"<p>ARC introduces four primary custom resource types under the <code>arc.bwi.de/v1alpha1</code> API group:</p> Resource Purpose Scope Order Declares intent to procure one or more artifacts with shared configuration defaults User-facing, high-level Fragment Represents a single artifact operation decomposed from an Order System-generated, execution unit Endpoint Defines a source or destination location with credentials Configuration, reusable ArtifactTypeDefinition Specifies processing rules and workflow templates for artifact types (e.g., \"oci\", \"helm\") Configuration, system-wide graph LR     subgraph \"Declarative Layer\"         Order[\"Order&lt;br/&gt;(User Input)\"]         OrderSpec[\"spec:&lt;br/&gt;- defaults&lt;br/&gt;- artifacts[]\"]     end      subgraph \"Generated Layer\"         Fragment1[\"Fragment-1\"]         Fragment2[\"Fragment-2\"]         FragmentN[\"Fragment-N\"]     end      subgraph \"Configuration\"         SrcEndpoint[\"Endpoint&lt;br/&gt;(Source)\"]         DstEndpoint[\"Endpoint&lt;br/&gt;(Destination)\"]         ATD[\"ArtifactTypeDefinition&lt;br/&gt;(e.g., 'oci')\"]         Secret[\"Secret&lt;br/&gt;(Credentials)\"]     end      subgraph \"Execution\"         WorkflowTemplate[\"WorkflowTemplate&lt;br/&gt;(Argo)\"]         Workflow1[\"Workflow Instance\"]         Workflow2[\"Workflow Instance\"]     end      Order --&gt;|\"contains\"| OrderSpec     OrderSpec --&gt;|\"generates\"| Fragment1     OrderSpec --&gt;|\"generates\"| Fragment2     OrderSpec --&gt;|\"generates\"| FragmentN      Fragment1 --&gt;|\"srcRef\"| SrcEndpoint     Fragment1 --&gt;|\"dstRef\"| DstEndpoint     Fragment1 --&gt;|\"type\"| ATD     Fragment2 --&gt;|\"references\"| SrcEndpoint     Fragment2 --&gt;|\"references\"| DstEndpoint      SrcEndpoint --&gt;|\"credentialRef\"| Secret     DstEndpoint --&gt;|\"credentialRef\"| Secret      ATD --&gt;|\"workflowTemplateRef\"| WorkflowTemplate     Fragment1 -.-&gt;|\"triggers\"| Workflow1     Fragment2 -.-&gt;|\"triggers\"| Workflow2     WorkflowTemplate -.-&gt;|\"instantiates\"| Workflow1     WorkflowTemplate -.-&gt;|\"instantiates\"| Workflow2"},{"location":"#key-components","title":"Key Components","text":""},{"location":"#arc-api-server","title":"ARC API Server","text":"<p>The ARC API Server is a Kubernetes Extension API Server implemented using the <code>k8s.io/apiserver</code> library. Key characteristics:</p> <ul> <li>Implementation Path: <code>pkg/apiserver/</code></li> <li>Storage Backend: Dedicated etcd instance (isolated from Kubernetes control plane etcd)</li> <li>Registry Pattern: Uses <code>pkg/registry/</code> for custom storage strategies per resource type</li> <li>API Group: <code>arc.bwi.de</code> with version <code>v1alpha1</code></li> <li>Integration: Registered with Kubernetes API Aggregation Layer to handle requests to <code>arc.bwi.de/*</code> paths</li> </ul> <p>The dedicated etcd approach provides:</p> <ul> <li>Isolation from the hosting cluster's control plane</li> <li>Flexibility to change storage backends if needed</li> <li>Protection against resource volume impacting cluster stability</li> </ul>"},{"location":"#order-controller","title":"Order Controller","text":"<p>The Order Controller implements the reconciliation loop for Order resources:</p> <ul> <li>Implementation Path: <code>pkg/controller/</code></li> <li>Framework: Uses <code>sigs.k8s.io/controller-runtime</code> (version 0.22.4)</li> <li> <p>Reconciliation Logic:</p> <ol> <li>Watch for Order create/update/delete events</li> <li>Validate endpoint references exist</li> <li>Apply defaults from Order.spec.defaults</li> <li>Generate Fragment resources (one per artifact entry)</li> <li>Lookup ArtifactTypeDefinition for each fragment's type</li> <li>Create Argo Workflow instances with appropriate WorkflowTemplate references</li> <li>Update Order status based on Fragment and Workflow statuses</li> <li>Handle finalizers for cleanup operations</li> </ol> </li> </ul> sequenceDiagram     participant User     participant arcctl     participant K8sAPI as \"Kubernetes API\"     participant ARCAPI as \"ARC API Server&lt;br/&gt;pkg/apiserver/\"     participant etcd as \"Dedicated etcd\"     participant OrderCtrl as \"Order Controller&lt;br/&gt;pkg/controller/\"     participant ArgoCtrl as \"Argo Controller\"     participant Workflow as \"Workflow Pod\"     participant Registry as \"External Registry\"      User-&gt;&gt;arcctl: \"arcctl oci pull alpine:3.18\"     arcctl-&gt;&gt;K8sAPI: \"Create Order CR\"     K8sAPI-&gt;&gt;ARCAPI: \"Forward to arc.bwi.de\"     ARCAPI-&gt;&gt;etcd: \"Store Order\"      etcd--&gt;&gt;OrderCtrl: \"Watch notification\"     OrderCtrl-&gt;&gt;OrderCtrl: \"Reconcile()\"     OrderCtrl-&gt;&gt;ARCAPI: \"Create Fragment CRs\"     ARCAPI-&gt;&gt;etcd: \"Store Fragments\"      OrderCtrl-&gt;&gt;ARCAPI: \"Get ArtifactTypeDefinition\"     ARCAPI--&gt;&gt;OrderCtrl: \"ATD with workflowTemplateRef\"      OrderCtrl-&gt;&gt;K8sAPI: \"Create Workflow CR\"     K8sAPI--&gt;&gt;ArgoCtrl: \"Workflow created\"      ArgoCtrl-&gt;&gt;Workflow: \"Start workflow pods\"     Workflow-&gt;&gt;ARCAPI: \"Read Endpoint configs\"     ARCAPI--&gt;&gt;Workflow: \"Endpoint details + secrets\"      Workflow-&gt;&gt;Registry: \"Pull artifact\"     Registry--&gt;&gt;Workflow: \"Artifact data\"      Workflow-&gt;&gt;Workflow: \"Security scan\"     Workflow-&gt;&gt;Registry: \"Push to destination\"      Workflow--&gt;&gt;ArgoCtrl: \"Workflow complete\"     ArgoCtrl-&gt;&gt;K8sAPI: \"Update Workflow status\"      OrderCtrl-&gt;&gt;ARCAPI: \"Update Order status\"     ARCAPI-&gt;&gt;etcd: \"Store status update\""},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#getting-started","title":"Getting started","text":"<p>Users interact with ARC primarily through the <code>arcctl</code> CLI tool, which provides commands for artifact operations and resource management. The CLI communicates with the Kubernetes API Server, which forwards ARC-specific requests to the ARC API Server extension. This creates a declarative workflow where users define desired artifact states, and the system executes the necessary operations.</p>"},{"location":"developer-guide/contributing/","title":"Artifact Conduit (ARC) Developer Guide","text":""},{"location":"developer-guide/contributing/#artifact-conduit-arc-developer-guide","title":"Artifact Conduit (ARC) Developer Guide","text":"<p>This guide provides technical information for developers contributing to the Artifact Conduit (ARC) project. It covers the development workflow, build system, code organization, and common development tasks. For detailed information about specific topics, see the referenced sections.</p>"},{"location":"developer-guide/contributing/#development-workflow-overview","title":"Development Workflow Overview","text":"<p>ARC follows a code-generation-heavy pattern typical in Kubernetes ecosystem projects. Changes to API types trigger code regeneration, which produces client libraries, OpenAPI specifications, and CRD manifests.</p>"},{"location":"developer-guide/contributing/#build-system","title":"Build System","text":"<p>The ARC build system uses a Makefile to orchestrate various tools, designed for reproducibility. All required tools are provided in the <code>bin/</code> directory.</p> Target Purpose Key Tools Used <code>make codegen</code> Generate client-go libraries &amp; OpenAPI <code>openapi-gen</code>, <code>kube_codegen.sh</code> <code>make manifests</code> Generate CRDs and RBAC manifests <code>controller-gen</code> <code>make fmt</code> Format code, add license headers <code>addlicense</code>, <code>go fmt</code> <code>make lint</code> Run linters and checks <code>golangci-lint</code>, <code>shellcheck</code>, <code>addlicense</code> <code>make test</code> Run all tests with coverage <code>ginkgo</code>, <code>setup-envtest</code> <code>make clean</code> Remove generated binaries -"},{"location":"developer-guide/contributing/#tool-versions","title":"Tool Versions","text":"<p>The system pins specific tool versions for reproducibility:</p> <ul> <li>BDD testing framework: <code>v2.27.2</code></li> <li>Go linter: <code>v2.5.0</code></li> <li>CRD/RBAC generator: <code>v0.19.0</code></li> <li>Kubernetes test API server: <code>release-0.22</code></li> <li>K8s for integration tests: <code>1.34.1</code></li> </ul>"},{"location":"developer-guide/contributing/#codebase-organization","title":"Codebase Organization","text":"<p>ARC codebase follows standard Kubernetes project conventions:</p> Directory Purpose Generated/Manual <code>api/arc/v1alpha1/</code> Custom resource type definitions Manual <code>client-go/</code> Client libraries for ARC resources Generated <code>pkg/apiserver/</code> Extension API server implementation Manual <code>pkg/controller/</code> Controller reconciliation logic Manual <code>pkg/registry/</code> Storage strategies for custom resources Manual <code>cmd/arcctl/</code> CLI tool implementation Manual <code>config/</code> Kubernetes manifests (CRDs, RBAC) Generated <code>hack/</code> Build and code generation scripts Manual"},{"location":"developer-guide/contributing/#code-generation-process","title":"Code Generation Process","text":"<p>ARC uses the Kubernetes code-generator to produce client libraries and OpenAPI specs.</p> <ul> <li><code>make codegen</code> triggers <code>hack/update-codegen.sh</code></li> <li>Generates:</li> <li>Client-go libraries in <code>client-go/</code></li> <li>OpenAPI specs</li> <li>CRD manifests</li> </ul> <p>See Client Libraries section for usage details.</p>"},{"location":"developer-guide/contributing/#testing-strategy","title":"Testing Strategy","text":"<p>ARC uses a multi-layered testing strategy:</p> <ul> <li>Unit Tests</li> <li>Integration Tests (uses <code>ENVTEST_K8S_VERSION=1.34.1</code>)</li> <li>Controller Tests via envtest</li> </ul> <p>Run all tests and generate coverage:</p> <pre><code>make test\n</code></pre> <p>Setup environment for integration tests:</p> <pre><code>setup-envtest\nexport ENVTEST_K8S_VERSION=1.34.1\n</code></pre> <p>Test coverage is tracked using Coveralls.</p>"},{"location":"developer-guide/contributing/#continuous-integration-ci-pipeline","title":"Continuous Integration (CI) Pipeline","text":"<p>Pipeline runs on every push and pull request, enforcing code quality and test coverage.</p> <ul> <li>Lint Job</li> <li><code>addlicense</code></li> <li><code>shellcheck</code></li> <li><code>golangci-lint</code></li> <li>Test Job (runs after Lint)</li> <li><code>make test</code></li> </ul> <p>For customization details, see <code>.github/workflows/golang.yaml</code>.</p>"},{"location":"developer-guide/contributing/#adding-a-new-custom-resource","title":"Adding a New Custom Resource","text":"<p>To introduce a new CRD:</p> <ol> <li>Create type definition in <code>api/arc/v1alpha1/</code></li> <li>Add OpenAPI model name</li> <li>Regenerate code via <code>make codegen</code></li> <li>Implement storage in <code>pkg/registry/</code></li> <li>Add controller logic in <code>pkg/controller/</code> if reconciliation is needed</li> </ol> <p>See <code>hack/update-codegen.sh</code> for implementation details.</p>"},{"location":"developer-guide/contributing/#modifying-existing-api-types","title":"Modifying Existing API Types","text":"<p>Typical steps:</p> <ol> <li>Edit types in <code>api/arc/v1alpha1/</code></li> <li>Run <code>make codegen</code></li> <li>Run <code>make manifests</code></li> <li>Run <code>make test</code></li> </ol> <p>Note: Breaking changes may affect existing clients. Follow semantic versioning and provide migration paths.</p>"},{"location":"developer-guide/contributing/#code-quality-linting","title":"Code Quality &amp; Linting","text":"<p>Lint and license checks before committing:</p> <ul> <li><code>addlicense</code> for Apache 2.0 headers</li> <li><code>shellcheck</code> for scripts in <code>hack/</code></li> <li><code>golangci-lint</code> for Go linting</li> </ul> <p>Fix issues with:</p> <pre><code>make fmt\nmake lint\n</code></pre>"},{"location":"developer-guide/dod/","title":"Definition of Done","text":""},{"location":"developer-guide/dod/#definition-of-done","title":"Definition of Done","text":"<p>TODO</p>"},{"location":"developer-guide/working-with-docs/","title":"Documentation Setup","text":""},{"location":"developer-guide/working-with-docs/#documentation-setup","title":"Documentation Setup","text":"<p>The documentation of the ARC project is written primarily using Markdown. All documentation related content can be found in https://github.com/opendefensecloud/artifact-conduit/tree/main/docs. New content also should be added there.</p> <p>To render the documentation with <code>mkdocs</code> locally use <code>make docs</code> and open the local page:</p> <pre><code>$ make docs\nmkdocs serve\nINFO    -  Building documentation...\nINFO    -  Cleaning site directory\nINFO    -  Documentation built in 0.22 seconds\nINFO    -  [13:29:25] Watching paths for changes: 'docs', 'mkdocs.yml'\nINFO    -  [13:29:25] Serving on http://127.0.0.1:8000/\n</code></pre>"},{"location":"developer-guide/adrs/000-Use-Markdown-Architectural-Decision-Records/","title":"Find a Common Way to Document Architectural Design Decsisions","text":""},{"location":"developer-guide/adrs/000-Use-Markdown-Architectural-Decision-Records/#find-a-common-way-to-document-architectural-design-decsisions","title":"Find a Common Way to Document Architectural Design Decsisions","text":""},{"location":"developer-guide/adrs/000-Use-Markdown-Architectural-Decision-Records/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>We want to record architectural decisions made in this project independent whether decisions concern the architecture (\"architectural decision record\"), the code, or other fields. Which format and structure should these records follow?</p>"},{"location":"developer-guide/adrs/000-Use-Markdown-Architectural-Decision-Records/#considered-options","title":"Considered Options","text":"<ul> <li>MADR\u00a04.0.0 \u2013 The Markdown Architectural Decision Records</li> <li>Michael Nygard's template\u00a0\u2013 The first incarnation of the term \"ADR\"</li> <li>Sustainable Architectural Decisions\u00a0\u2013 The Y-Statements</li> <li>Other templates listed at\u00a0https://github.com/joelparkerhenderson/architecture_decision_record</li> <li>Formless \u2013 No conventions for file format and structure</li> </ul>"},{"location":"developer-guide/adrs/000-Use-Markdown-Architectural-Decision-Records/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"MADR 4.0.0\", because</p> <ul> <li>Implicit assumptions should be made explicit. Design documentation is important to enable people understanding the decisions later on. See also\u00a0\"A rational design process: How and why to fake it\".</li> <li>MADR allows for structured capturing of any decision.</li> <li>The MADR format is lean and fits our development style.</li> <li>The MADR structure is comprehensible and facilitates usage &amp; maintenance.</li> <li>The MADR project is vivid.</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/","title":"Evaluate Future ARC Architecture Based on Predecessors","text":""},{"location":"developer-guide/adrs/001-ARC-Architecture/#evaluate-future-arc-architecture-based-on-predecessors","title":"Evaluate Future ARC Architecture Based on Predecessors","text":""},{"location":"developer-guide/adrs/001-ARC-Architecture/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>This ADR is about finding the right architecture for the ARC suite of services based on the knowledge gained during the internal predecessors of this project.</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#glossary","title":"Glossary","text":"<ul> <li><code>arcctl</code>: Command line utility to interact with the ARC API.</li> <li><code>Order</code>: Represents an order of one or more artifacts. Even ordering artifacts that may exist in the future can be reference here using semver expressions for example.</li> <li><code>OrderFragment</code>: Represents a single artifact order which is part of an <code>Order</code>.</li> <li><code>OrderTypeDefinition</code>: Defines rules and defaults for a specific order type like 'OCI'. References a certain workflow to use for that type.</li> <li><code>Endpoint</code>: General term for source or destination. Can be a source or destination for artifacts. Includes optional credentials to access it.</li> <li><code>WorkflowTemplate</code>: Argo Workflows, see https://argo-workflows.readthedocs.io/en/latest/fields/#workflowtemplate</li> <li><code>Workflow</code>: Argo Workflows, see https://argo-workflows.readthedocs.io/en/latest/fields/#workflow</li> <li><code>ARC API Server</code>: A Kubernetes Extension API Server which handles storage of ARC API</li> <li><code>Order Controller</code>: A Kubernetes Controller which reconciles <code>Orders</code>, splits up <code>Order</code> resources into <code>OrderFragment</code> Resources, creates <code>Workflow</code> resources for necessary workload</li> <li><code>ArtifactTypeDefinition</code>: Specifies the processing rules and workflow templates for artifact types (e.g. <code>oci</code>, <code>helm</code>).</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#considered-options","title":"Considered Options","text":""},{"location":"developer-guide/adrs/001-ARC-Architecture/#classic-kubernetes-operators","title":"Classic Kubernetes Operators","text":"<ul> <li>CRDs are used to interact with ARC via the Kubernetes API Server.</li> <li>Several operators come into play which reconcile the different custom resources.</li> <li>A sharding mechanism is implemented to be able to scale the workers horizontally and give every worker a given chunk of resources to reconcile.</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#pros","title":"Pros","text":"<ul> <li>CRDs and Kubernetes are relatively simple to implement</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#cons","title":"Cons","text":"<ul> <li>Storage may be limited by <code>etcd</code> and can bring the control plane of Kubernetes into trouble if too many resources are present</li> <li>The necessity to implement sharding may be hard work and error prone</li> <li>Thus said it may not scale in way necessary for such a solution</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#extension-api-server-and-cncf-landscape-tooling","title":"Extension API Server and CNCF Landscape Tooling","text":""},{"location":"developer-guide/adrs/001-ARC-Architecture/#flavor-a","title":"Flavor A","text":"<p>Flavor uses several controllers to handle different parts of the API. Orders are reconciled and converted to hydrated Orders which contain the source and destination information along with the artifact to process. This information are published to some message queue which is subscribed by workers working on that queue. Optionally KEDA is used to scale, handle quotas and fairness. The database to be used for the API Server is etcd.</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#flavor-b","title":"Flavor B","text":"<p>Same as Flavor A except the database for the API Server is something like Postgres instead of etcd. Additionally the option is considered to let the controller access the Postgres directly to reconcile without using the Kubernetes API Server.</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#flavor-c","title":"Flavor C","text":"<p>Same as Flavor B except that no message queue is used but the job queue is stored directly in the Postgres database.</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#flavor-d","title":"Flavor D","text":"<p>Same as Flavor A except that no message queue is used. The Order controller creates hydrated orders directly in <code>etcd</code> as readonly resource which is then consumed by workers directly. This approach needs some kind of sharding mechanism to have the workers to know which shard of resources they need to handle.</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#flavor-e","title":"Flavor E","text":"<p>This flavor is the most compelling due to the reduced amount of code that is necessary to bring this solution to live. etcd is used as storage for the API server. Argo Workflows is used to build workflows which do the steps necessary to process one artifact. Kueue can be used to bring fairness, scaling, quotas into play which workflows. The order controller creates \"jobs\" which are actually Argo Workflows.</p> <p>This option is described in detail in the following document.</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#technology","title":"Technology","text":"<ul> <li>Instead of CRDs, <code>ARC</code> uses an Extension API Server via the Kubernetes API Aggregation Layer to handle API requests.</li> <li>This gives it the possibility to use a dedicated <code>etcd</code> or a even more suitable storage backend for the high amount of resources and status information in case this is necessary.</li> <li>While <code>etcd</code> still can be used as storage backend, it is one separated from the <code>etcd</code> used by the Kubernetes control plane and reduces the risk of bringing the whole cluster into trouble.</li> <li>Additional links</li> <li>https://github.com/kubernetes-sigs/apiserver-runtime</li> <li>https://github.com/kubernetes/sample-apiserver/tree/master</li> <li>Utilize Argo Workflows to handle the workflows necessary to process different artifact types</li> <li>Optionally use Kueue to handle quotas and enhanced scheduling</li> <li>Namespaces are used to separate resources in a multi-tenant environment.</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#architecture-diagram","title":"Architecture Diagram","text":"<p>Overview Diagram</p> <p></p> <p>API Concept Diagram</p> --- config:   layout: elk --- flowchart LR  subgraph subGraph0[\"Declarative Layer\"]         Order[\"Order (User Input)\"]         Spec[\"spec:&lt;br&gt;- defaults&lt;br&gt;- artifacts[]\"]   end  subgraph subGraph1[\"Generated Layer\"]         Fragment1[\"Fragment-1\"]         Fragment2[\"Fragment-2\"]         FragmentN[\"Fragment-N\"]   end  subgraph Configuration[\"Configuration\"]         ArtifactTypeDef@{ label: \"ArtifactTypeDefinition (e.g., 'oci')\" }         EndpointSrc[\"Endpoint (Source)\"]         EndpointDst[\"Endpoint (Destination)\"]         Secret[\"Secret (Credentials)\"]   end  subgraph Execution[\"Execution\"]         WorkflowTemplate[\"WorkflowTemplate (Argo)\"]         WorkflowInstance1[\"Workflow Instance\"]         WorkflowInstance2[\"Workflow Instance\"]   end     Order -- contains --&gt; Spec     Spec -- generates --&gt; Fragment1 &amp; Fragment2 &amp; FragmentN     Fragment1 -- type --&gt; ArtifactTypeDef     Fragment2 -- type --&gt; ArtifactTypeDef     Fragment1 -- srcRef --&gt; EndpointSrc     Fragment2 -- srcRef --&gt; EndpointSrc     Fragment1 -- dstRef --&gt; EndpointDst     Fragment2 -- dstRef --&gt; EndpointDst     Fragment1 -- references --&gt; EndpointSrc &amp; EndpointDst     Fragment2 -- references --&gt; EndpointSrc &amp; EndpointDst     EndpointSrc -- credentialRef --&gt; Secret     EndpointDst -- credentialRef --&gt; Secret     ArtifactTypeDef -- workflowTemplateRef --&gt; WorkflowTemplate     Fragment1 -- triggers --&gt; WorkflowTemplate     Fragment2 -- triggers --&gt; WorkflowTemplate     WorkflowTemplate -- instantiates --&gt; WorkflowInstance1 &amp; WorkflowInstance2     ArtifactTypeDef@{ shape: rect}  <p>The solution shows the ARC API Server which handles storage for the custom resources / API of ARC. <code>etcd</code> is used as storage solution. <code>Order Controller</code> is a classic Kubernetes controller implementation which reconciles <code>Orders</code> and <code>Endpoints</code>. An <code>Order</code> contains the information what artifacts should be processed. An <code>Endpoint</code> contains the information about a source or destination for artifacts. The <code>Order Controller</code> creates <code>Fragment</code> resources which are single artifacts decomposed from an <code>Order</code>. An <code>ArtifactTypeDefinition</code> specifies the processing rules and workflow templates for artifact types (e.g. <code>oci</code>, <code>helm</code>).</p>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#pros_1","title":"Pros","text":"<ul> <li>Using dedicated <code>etcd</code> does not clutter the infra etcd</li> <li>Storage can be changed later on if necessary</li> <li>Keep the declarative style of Kubernetes while having complete freedom on the API implementation</li> <li>Argo Workflows allows us to focus on the domain of the product without reinventing the wheel</li> <li>Qotas and Fairness easy without writing code via Kueue</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#cons_1","title":"Cons","text":"<ul> <li>Building addon apiservers directly on the raw api-machinery libraries requires non-trivial code that must be maintained and rebased as the raw libraries change.</li> <li>Steep learning curve when starting the project and steeper learning curve when joining the project.</li> </ul>"},{"location":"developer-guide/adrs/001-ARC-Architecture/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen Option: Solution A.</p> <p>Because the solution is the one that provides the most flexibility while the necessity to write own code for many parts is minimized. The flexibility comes from utilizing the CNCF projects Argo Workflows and Kueue for building the workflow engine. The project itself can focus on the order process and the handling of endpoints.</p>"},{"location":"developer-guide/adrs/002-ARC-API/","title":"Define an Optimal API for the Project Beginning","text":""},{"location":"developer-guide/adrs/002-ARC-API/#define-an-optimal-api-for-the-project-beginning","title":"Define an Optimal API for the Project Beginning","text":""},{"location":"developer-guide/adrs/002-ARC-API/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>This ADR is about finding the right API for ARC.</p>"},{"location":"developer-guide/adrs/002-ARC-API/#proposed-solution","title":"Proposed Solution","text":"<p>Options were discussed and documented here: https://app.bwi.conceptboard.com/board/u9c0-4nk5-rrhd-knre-6cfn</p> <pre><code>apiVersion: arc.bwi.de/v1alpha1\nkind: Order\nmetadata:\n  name: example-order\nspec:\n  defaults:\n    srcRef:\n      name: docker-hub\n      namespace: default # optional\n    dstRef:\n      name: internal-registry\n  artifacts:\n    - type: oci # artifactType, correcesponds to workflow\n      dstRef:\n        name: other-internal-registry\n        namespace: default # optional\n      spec:\n        image: library/alpine:3.18\n        override: myteam/alpine:3.18-dev # default alpine:3.18; support CEL?\n    - type: oci\n      spec:\n        image: library/ubuntu:1.0\n    - type: helm\n      srcRef:\n        name: jetstack-helm\n      dstRef:\n        name: internal-helm-registry\n      spec:\n        name: cert-manager\n        version: \"47.11\"\n        override: helm-charts/cert-manager:47.11\n</code></pre> <pre><code>apiVersion: arc.bwi.de/v1alpha1\nkind: Fragment\nmetadata:\n  name: example-order-1 # sha256 for procedural\nspec:\n  type: oci # artifactType, correcesponds to workflow\n  srcRef: # required\n    name: lala\n  dstRef: #required\n    name: other-internal-registry\n    namespace: default # optional\n  spec:\n    image: library/alpine:3.18\n    override: myteam/alpine:3.18-dev # default alpine:3.18; support CEL?\n</code></pre> <pre><code>apiVersion: arc.bwi.de/v1alpha1\nkind: Endpoint\nmetadata:\n  name: internal-registry\nspec:\n  type: oci # Endpoint Type! set valid types on controller manager?\n  remoteURL: https://artifactory.example.com/artifactory/ace-oci-local\n  secretRef: # STANDARDIZED!\n    name: internal-registry-credentials\n  usage: PullOnly | PushOnly | All # enum\n</code></pre> <pre><code>apiVersion: arc.bwi.de/v1alpha1\nkind: ArtifactTypeDefinition\nmetadata:\n  name: oci\nspec:\n  rules:\n    srcTypes:\n      - s3 # Endpoint Types!\n      - oci\n      - helm\n    dstTypes:\n      - oci\n  defaults:\n    dstRef: internal-registry\n  workflowTemplateRef: # argo.Workflow\n</code></pre>"},{"location":"operator-manual/installation/","title":"Installation","text":""},{"location":"operator-manual/installation/#installation","title":"Installation","text":"<p>TODO</p>"},{"location":"operator-manual/new-features/","title":"New Features","text":""},{"location":"operator-manual/new-features/#new-features","title":"New Features","text":"<p>TODO</p>"},{"location":"operator-manual/releases/","title":"Releases","text":""},{"location":"operator-manual/releases/#releases","title":"Releases","text":"<p>TODO</p>"},{"location":"operator-manual/security/","title":"Security","text":""},{"location":"operator-manual/security/#security","title":"Security","text":"<p>TODO</p>"},{"location":"operator-manual/upgrading/","title":"Upgrading","text":""},{"location":"operator-manual/upgrading/#upgrading","title":"Upgrading","text":"<p>TODO</p>"},{"location":"user-guide/core-concepts/","title":"Core Concepts","text":""},{"location":"user-guide/core-concepts/#core-concepts","title":"Core Concepts","text":"<p>This document provides a comprehensive overview of the Artifact Conduit (ARC) system architecture, covering its design principles, core components, and how they interact.</p>"},{"location":"user-guide/core-concepts/#purpose-and-scope","title":"Purpose and Scope","text":"<p>ARC is a Kubernetes-native artifact management system designed to securely transport artifacts (OCI images, Helm charts, generic files) across network boundaries, particularly into air-gapped environments. The architecture employs a Kubernetes Extension API Server pattern to provide declarative resource management while maintaining flexibility for future storage backend changes.</p>"},{"location":"user-guide/core-concepts/#architectural-decision","title":"Architectural Decision","text":"<p>ARC's architecture is based on Architectural Decision Record 001, which selected an Extension API Server approach over traditional Custom Resource Definitions (CRDs). This design provides several key advantages:</p> Aspect Decision Rationale API Extension Kubernetes API Aggregation Layer Allows dedicated etcd instance, avoiding cluster control plane pollution Storage Backend Dedicated etcd (replaceable) Enables future migration to alternative storage if needed Workflow Engine Argo Workflows Leverages proven workflow orchestration without reinventing execution logic Declarative Model Kubernetes-style resources Maintains familiar kubectl/GitOps patterns for users <p>The Extension API Server pattern allows ARC to present a Kubernetes-native API surface while maintaining complete control over storage implementation and API behavior.</p>"},{"location":"user-guide/core-concepts/#system-components","title":"System Components","text":""},{"location":"user-guide/core-concepts/#component-overview","title":"Component Overview","text":"graph TB     subgraph \"Control Plane\"         K8sAPI[\"Kubernetes API Server\"]         APIAgg[\"API Aggregation Layer\"]     end      subgraph \"ARC System\"         APIServer[\"arc-apiserver&lt;br/&gt;(Extension API Server)\"]         etcd[\"Dedicated etcd&lt;br/&gt;(Storage Backend)\"]         CtrlMgr[\"arc-controller-manager\"]         OrderCtrl[\"OrderReconciler\"]     end      subgraph \"Custom Resources\"         Order[\"Order CR\"]         Fragment[\"Fragment CR\"]         Endpoint[\"Endpoint CR\"]         ATD[\"ArtifactTypeDefinition CR\"]     end      subgraph \"Execution Layer\"         Argo[\"Argo Workflows\"]         WorkflowTemplate[\"WorkflowTemplate\"]         Workflow[\"Workflow Instance\"]     end      subgraph \"External Systems\"         Registry[\"OCI Registries\"]         S3[\"S3 Storage\"]         Scanners[\"Security Scanners\"]     end      K8sAPI --&gt; APIAgg     APIAgg --&gt; APIServer     APIServer --&gt; etcd      CtrlMgr --&gt; OrderCtrl     OrderCtrl --&gt; K8sAPI     OrderCtrl --&gt; APIServer      Order --&gt; OrderCtrl     OrderCtrl --&gt; Fragment     OrderCtrl --&gt; Argo      Fragment --&gt; Endpoint     Fragment --&gt; ATD     ATD --&gt; WorkflowTemplate     Argo --&gt; Workflow      Workflow --&gt; Registry     Workflow --&gt; S3     Workflow --&gt; Scanners"},{"location":"user-guide/core-concepts/#arc-api-server","title":"ARC API Server","text":"<p>The API Server implements the Kubernetes Extension API Server pattern, registering with the Kubernetes API Aggregation Layer to handle requests for the <code>arc.bwi.de</code> API group.</p> <p>Key Characteristics:</p> Property Value Package <code>pkg/apiserver/</code> API Group <code>arc.bwi.de/v1alpha1</code> Storage Dedicated etcd cluster Registration Via APIService resource <p>The API Server is built using <code>apiserver-runtime</code> and <code>sample-apiserver</code> patterns, providing:</p> <ul> <li>Native Kubernetes authentication and authorization integration</li> <li>OpenAPI schema generation</li> <li>Support for standard Kubernetes API conventions (List, Watch, Get, Create, Update, Delete, Patch)</li> <li>Server-side apply functionality</li> </ul> <p>The test environment bootstraps the API Server programmatically for integration testing:</p> graph LR     TestEnv[\"envtest.Environment\"]     K8sControlPlane[\"envtest Control Plane\"]     APIServerProc[\"arc-apiserver Process\"]     APIService[\"APIService Resource\"]      TestEnv --&gt; K8sControlPlane     TestEnv --&gt; APIServerProc     APIServerProc --&gt; K8sControlPlane     K8sControlPlane --&gt; APIService"},{"location":"user-guide/core-concepts/#controller-manager","title":"Controller Manager","text":"<p>The controller manager binary (<code>arc-controller-manager</code>) hosts the Order controller and other reconciliation loops.</p> <p>Binary Location: cmd/arc-controller-manager/main.go:1-196</p> <p>Configuration:</p> Flag Default Purpose <code>--metrics-bind-address</code> <code>0</code> Metrics endpoint address <code>--health-probe-bind-address</code> <code>:8081</code> Health check endpoint <code>--leader-elect</code> <code>false</code> Enable leader election for HA <code>--metrics-secure</code> <code>true</code> Serve metrics over HTTPS <p>The manager initializes with:</p> <ul> <li>Kubernetes client-go scheme + ARC custom resources (cmd/arc-controller-manager/main.go:37-40)</li> <li>Controller-runtime manager with leader election support (cmd/arc-controller-manager/main.go:150-162)</li> <li>OrderReconciler registration (cmd/arc-controller-manager/main.go:173-178)</li> <li>Health and readiness checks (cmd/arc-controller-manager/main.go:182-189)</li> </ul>"},{"location":"user-guide/core-concepts/#resource-model","title":"Resource Model","text":""},{"location":"user-guide/core-concepts/#resource-hierarchy","title":"Resource Hierarchy","text":"graph TB     User[\"User/Operator\"]      subgraph \"Declarative Layer\"         Order[\"Order&lt;br/&gt;apiVersion: arc.bwi.de/v1alpha1&lt;br/&gt;kind: Order\"]         OrderSpec[\"spec:&lt;br/&gt;- defaults&lt;br/&gt;- artifacts[]\"]         OrderDefaults[\"defaults:&lt;br/&gt;- srcRef&lt;br/&gt;- dstRef\"]         OrderArtifacts[\"artifacts:&lt;br/&gt;- type&lt;br/&gt;- spec&lt;br/&gt;- srcRef/dstRef overrides\"]     end      subgraph \"Execution Layer\"         Fragment1[\"Fragment&lt;br/&gt;apiVersion: arc.bwi.de/v1alpha1&lt;br/&gt;kind: Fragment\"]         Fragment2[\"Fragment\"]         FragmentSpec[\"spec:&lt;br/&gt;- type&lt;br/&gt;- srcRef&lt;br/&gt;- dstRef&lt;br/&gt;- spec (type-specific)\"]     end      subgraph \"Configuration Layer\"         Endpoint1[\"Endpoint&lt;br/&gt;kind: Endpoint\"]         Endpoint2[\"Endpoint\"]         EndpointSpec[\"spec:&lt;br/&gt;- type&lt;br/&gt;- remoteURL&lt;br/&gt;- secretRef&lt;br/&gt;- usage\"]          ATD[\"ArtifactTypeDefinition&lt;br/&gt;kind: ArtifactTypeDefinition\"]         ATDSpec[\"spec:&lt;br/&gt;- rules&lt;br/&gt;- workflowTemplateRef\"]          Secret[\"Secret&lt;br/&gt;(credentials)\"]     end      User --&gt; Order     Order --&gt; OrderSpec     OrderSpec --&gt; OrderDefaults     OrderSpec --&gt; OrderArtifacts      OrderArtifacts -.generates.-&gt; Fragment1     OrderArtifacts -.generates.-&gt; Fragment2      Fragment1 --&gt; FragmentSpec     FragmentSpec --&gt; Endpoint1     FragmentSpec --&gt; Endpoint2     FragmentSpec --&gt; ATD      Endpoint1 --&gt; EndpointSpec     EndpointSpec --&gt; Secret     ATD --&gt; ATDSpec"},{"location":"user-guide/core-concepts/#resource-definitions","title":"Resource Definitions","text":""},{"location":"user-guide/core-concepts/#order","title":"Order","text":"<p>High-level declarative resource specifying one or more artifacts to process.</p> <p>API Structure:</p> <ul> <li>Group: <code>arc.bwi.de</code></li> <li>Version: <code>v1alpha1</code></li> <li>Kind: <code>Order</code></li> <li>Spec Fields:</li> <li><code>defaults</code>: Default source and destination endpoints</li> <li><code>artifacts</code>: Array of artifact specifications</li> </ul>"},{"location":"user-guide/core-concepts/#fragment","title":"Fragment","text":"<p>Represents a single artifact operation, generated from Order resources by the Order controller.</p> <p>Generation Logic: The OrderReconciler decomposes an Order into individual Fragments, applying defaults from the Order spec to each Fragment that doesn't specify its own <code>srcRef</code> or <code>dstRef</code>.</p>"},{"location":"user-guide/core-concepts/#endpoint","title":"Endpoint","text":"<p>Defines connection details for artifact sources and destinations.</p> <p>Spec Fields:</p> <ul> <li><code>type</code>: Endpoint type (e.g., <code>oci</code>, <code>s3</code>, <code>helm</code>)</li> <li><code>remoteURL</code>: Connection URL</li> <li><code>secretRef</code>: Reference to Secret containing credentials</li> <li><code>usage</code>: Enum (<code>PullOnly</code>, <code>PushOnly</code>, <code>All</code>)</li> </ul>"},{"location":"user-guide/core-concepts/#artifacttypedefinition","title":"ArtifactTypeDefinition","text":"<p>Defines processing rules and workflow templates for specific artifact types.</p> <p>Spec Fields:</p> <ul> <li><code>rules</code>: Validation rules for source and destination endpoint types</li> <li><code>defaults</code>: Default endpoint references</li> <li><code>workflowTemplateRef</code>: Reference to Argo WorkflowTemplate</li> </ul>"},{"location":"user-guide/core-concepts/#controller-architecture","title":"Controller Architecture","text":""},{"location":"user-guide/core-concepts/#order-reconciliation-flow","title":"Order Reconciliation Flow","text":"sequenceDiagram     participant User     participant K8sAPI as \"Kubernetes API\"     participant ARCAPI as \"ARC API Server\"     participant OrderReconciler as \"OrderReconciler&lt;br/&gt;(pkg/controller)\"     participant etcd as \"etcd Storage\"     participant Argo as \"Argo Workflows\"      User-&gt;&gt;K8sAPI: Create Order resource     K8sAPI-&gt;&gt;ARCAPI: Forward arc.bwi.de request     ARCAPI-&gt;&gt;etcd: Store Order      Note over OrderReconciler: Watch loop detects change      etcd--&gt;&gt;OrderReconciler: Order event     OrderReconciler-&gt;&gt;OrderReconciler: Reconcile()      OrderReconciler-&gt;&gt;ARCAPI: List existing Fragments for Order     ARCAPI--&gt;&gt;OrderReconciler: Fragment list      OrderReconciler-&gt;&gt;OrderReconciler: Calculate desired Fragments&lt;br/&gt;from Order.spec.artifacts      OrderReconciler-&gt;&gt;ARCAPI: Create/Update Fragments     ARCAPI-&gt;&gt;etcd: Store Fragments      OrderReconciler-&gt;&gt;ARCAPI: Get ArtifactTypeDefinition     ARCAPI--&gt;&gt;OrderReconciler: ATD with workflowTemplateRef      OrderReconciler-&gt;&gt;K8sAPI: Create Workflow (via Argo API)     K8sAPI-&gt;&gt;Argo: Workflow created      Argo-&gt;&gt;Argo: Execute workflow      Argo-&gt;&gt;K8sAPI: Update Workflow status     K8sAPI--&gt;&gt;OrderReconciler: Status change event      OrderReconciler-&gt;&gt;ARCAPI: Update Order status     ARCAPI-&gt;&gt;etcd: Store updated status <p>The OrderReconciler implements the controller-runtime <code>Reconciler</code> interface and is registered in the controller manager.</p> <p>Reconciliation Logic:</p> <ol> <li>Fetch Order resource</li> <li>Generate Fragment specifications from <code>Order.spec.artifacts</code></li> <li>Apply defaults from <code>Order.spec.defaults</code> to Fragments</li> <li>Create/update Fragment resources via ARC API Server</li> <li>Lookup ArtifactTypeDefinition for each Fragment type</li> <li>Create Argo Workflow instances using WorkflowTemplate from ATD</li> <li>Update Order status based on Fragment and Workflow states</li> </ol>"},{"location":"user-guide/core-concepts/#storage-architecture","title":"Storage Architecture","text":""},{"location":"user-guide/core-concepts/#dedicated-etcd-instance","title":"Dedicated etcd Instance","text":"<p>Unlike CRD-based solutions that share the cluster's etcd, ARC uses a dedicated etcd cluster. This architectural choice provides:</p> Benefit Description Isolation ARC resource storage doesn't impact cluster control plane Scalability Independent scaling for high artifact throughput Flexibility Storage backend can be replaced without API changes Performance Optimized storage parameters for ARC's access patterns <p>The API Server connects to etcd using standard etcd v3 client configuration. In the test environment, this is provided by envtest's embedded etcd:</p> <p>pkg/envtest/environment.go:56 - The API Server is configured with etcd servers from the test environment's control plane.</p>"},{"location":"user-guide/core-concepts/#workflow-integration","title":"Workflow Integration","text":""},{"location":"user-guide/core-concepts/#argo-workflows-execution-model","title":"Argo Workflows Execution Model","text":"<p>ARC delegates actual artifact processing to Argo Workflows, which provides:</p> <ul> <li>DAG-based workflow execution</li> <li>Container-native artifact handling</li> <li>Retry and failure handling</li> <li>Status reporting</li> </ul> graph TB     subgraph \"ARC Resources\"         Fragment[\"Fragment\"]         ATD[\"ArtifactTypeDefinition\"]         Endpoint1[\"Endpoint (source)\"]         Endpoint2[\"Endpoint (destination)\"]     end      subgraph \"Argo Resources\"         WorkflowTemplate[\"WorkflowTemplate&lt;br/&gt;(defines steps)\"]         Workflow[\"Workflow&lt;br/&gt;(execution instance)\"]     end      subgraph \"Workflow Steps\"         PullStep[\"Pull Artifact&lt;br/&gt;(from srcRef)\"]         ScanStep[\"Security Scan&lt;br/&gt;(Trivy, ClamAV)\"]         ValidateStep[\"Validate&lt;br/&gt;(signatures, policies)\"]         PushStep[\"Push Artifact&lt;br/&gt;(to dstRef)\"]     end      Fragment --&gt; ATD     ATD --&gt; WorkflowTemplate     Fragment --&gt; Workflow     WorkflowTemplate --&gt; Workflow      Fragment --&gt; Endpoint1     Fragment --&gt; Endpoint2      Workflow --&gt; PullStep     PullStep --&gt; ScanStep     ScanStep --&gt; ValidateStep     ValidateStep --&gt; PushStep      Endpoint1 -.credentials.-&gt; PullStep     Endpoint2 -.credentials.-&gt; PushStep <p>Workflow Creation: The OrderReconciler creates Workflow instances by:</p> <ol> <li>Reading the <code>workflowTemplateRef</code> from the ArtifactTypeDefinition</li> <li>Instantiating a Workflow from the template</li> <li>Passing Fragment metadata and Endpoint references as workflow parameters</li> <li>Submitting the Workflow to Argo via Kubernetes API</li> </ol> <p>Status Propagation: Workflow status changes are watched by the OrderReconciler and propagated to Fragment and Order status fields.</p>"},{"location":"user-guide/core-concepts/#testing-infrastructure","title":"Testing Infrastructure","text":""},{"location":"user-guide/core-concepts/#test-environment-architecture","title":"Test Environment Architecture","text":"graph TB     subgraph \"Test Suite\"         TestCode[\"Integration Tests&lt;br/&gt;(Ginkgo)\"]     end      subgraph \"envtest.Environment\"         EnvtestCtrl[\"envtest Control Plane&lt;br/&gt;(API Server + etcd)\"]         EnvtestEtcd[\"envtest etcd\"]          APIServerProc[\"arc-apiserver Process&lt;br/&gt;(started via buildutils)\"]          APIService[\"APIService Resource&lt;br/&gt;(registers arc.bwi.de)\"]     end      subgraph \"Test Resources\"         TestNS[\"Test Namespace\"]         TestOrder[\"Test Order\"]         TestFragment[\"Test Fragment\"]     end      TestCode --&gt; EnvtestCtrl     TestCode --&gt; APIServerProc      EnvtestCtrl --&gt; EnvtestEtcd     EnvtestCtrl --&gt; APIService      APIServerProc --&gt; EnvtestEtcd     APIService --&gt; APIServerProc      TestCode --&gt; TestNS     TestCode --&gt; TestOrder     TestCode --&gt; TestFragment      TestOrder -.stored in.-&gt; EnvtestEtcd     TestFragment -.stored in.-&gt; EnvtestEtcd <p>The test environment (<code>pkg/envtest/environment.go</code>) provides a complete ARC deployment for integration testing:</p> <p>Initialization: pkg/envtest/environment.go:30-40</p> <ul> <li>Creates envtest Kubernetes environment with APIService definitions</li> <li>Starts arc-apiserver binary via buildutils</li> <li>Configures API Server to use envtest etcd</li> <li>Waits for APIService readiness</li> </ul> <p>Test Setup: pkg/apiserver/suite_test.go:67-83</p> <ul> <li>Creates isolated test namespaces per test case</li> <li>Provides Kubernetes client configured for ARC resources</li> <li>Automatic cleanup on test completion</li> </ul> <p>Sources: pkg/envtest/environment.go:1-93, pkg/apiserver/suite_test.go:1-84</p>"},{"location":"user-guide/core-concepts/#component-interactions","title":"Component Interactions","text":""},{"location":"user-guide/core-concepts/#request-flow-for-artifact-processing","title":"Request Flow for Artifact Processing","text":"sequenceDiagram     participant CLI as \"arcctl CLI\"     participant K8sAPI as \"Kubernetes API\"     participant APIAgg as \"API Aggregation\"     participant ARCAPI as \"arc-apiserver\"     participant etcd as \"Dedicated etcd\"     participant Ctrl as \"OrderReconciler\"     participant Argo as \"Argo Controller\"     participant Worker as \"Workflow Pod\"     participant Registry as \"OCI Registry\"      CLI-&gt;&gt;K8sAPI: POST /apis/arc.bwi.de/v1alpha1/orders     K8sAPI-&gt;&gt;APIAgg: Route to arc.bwi.de     APIAgg-&gt;&gt;ARCAPI: Forward request     ARCAPI-&gt;&gt;etcd: Write Order     etcd--&gt;&gt;ARCAPI: Success     ARCAPI--&gt;&gt;CLI: Order created      Note over Ctrl: Watch event received      Ctrl-&gt;&gt;ARCAPI: GET Order     ARCAPI-&gt;&gt;etcd: Read Order     etcd--&gt;&gt;ARCAPI: Order data     ARCAPI--&gt;&gt;Ctrl: Order object      Ctrl-&gt;&gt;Ctrl: Generate Fragments      Ctrl-&gt;&gt;ARCAPI: POST Fragments     ARCAPI-&gt;&gt;etcd: Write Fragments      Ctrl-&gt;&gt;ARCAPI: GET ArtifactTypeDefinition     ARCAPI-&gt;&gt;etcd: Read ATD     etcd--&gt;&gt;ARCAPI: ATD with workflowTemplateRef     ARCAPI--&gt;&gt;Ctrl: ATD object      Ctrl-&gt;&gt;K8sAPI: POST Workflow     K8sAPI-&gt;&gt;Argo: Workflow created      Argo-&gt;&gt;K8sAPI: Create Workflow Pod     K8sAPI-&gt;&gt;Worker: Start Pod      Worker-&gt;&gt;ARCAPI: GET Endpoints     ARCAPI-&gt;&gt;etcd: Read Endpoints     etcd--&gt;&gt;ARCAPI: Endpoint configs     ARCAPI--&gt;&gt;Worker: Endpoint data      Worker-&gt;&gt;Registry: Pull artifact (source)     Registry--&gt;&gt;Worker: Artifact data      Worker-&gt;&gt;Worker: Security scan      Worker-&gt;&gt;Registry: Push artifact (destination)     Registry--&gt;&gt;Worker: Success      Worker-&gt;&gt;K8sAPI: Update Workflow status     K8sAPI--&gt;&gt;Ctrl: Status event      Ctrl-&gt;&gt;ARCAPI: PATCH Order status     ARCAPI-&gt;&gt;etcd: Update Order status <p>This sequence shows the complete lifecycle from user command to artifact delivery, highlighting the separation between declarative resource management (ARC API Server) and execution (Argo Workflows).</p>"},{"location":"user-guide/core-concepts/#design-principles","title":"Design Principles","text":""},{"location":"user-guide/core-concepts/#separation-of-concerns","title":"Separation of Concerns","text":"Layer Responsibility Implementation API Layer Resource CRUD, validation, storage arc-apiserver + etcd Control Layer Reconciliation, Fragment generation OrderReconciler Execution Layer Artifact processing, scanning Argo Workflows Configuration Layer Endpoint definitions, type rules Endpoint, ATD resources"},{"location":"user-guide/core-concepts/#declarative-vs-imperative","title":"Declarative vs. Imperative","text":"<p>ARC follows Kubernetes conventions:</p> <ul> <li>Declarative: Users create Order resources describing desired artifacts</li> <li>Reconciliation: Controllers continuously reconcile actual state toward desired state</li> <li>Status Reporting: Status fields reflect current state and progress</li> </ul>"},{"location":"user-guide/core-concepts/#extension-api-server-benefits","title":"Extension API Server Benefits","text":"<p>The Extension API Server pattern provides:</p> <ol> <li>Future-Proof Storage: etcd can be replaced with alternative storage without changing the API</li> <li>Performance Isolation: High-volume artifact operations don't impact cluster control plane</li> <li>Custom Behavior: Full control over API semantics, validation, and storage strategies</li> <li>Standard Tooling: Compatible with kubectl, client-go, and GitOps tools</li> </ol> <p>Trade-offs:</p> <ul> <li>More complex deployment (requires APIService registration)</li> <li>Steeper learning curve for contributors</li> <li>Additional operational considerations (etcd management)</li> </ul>"},{"location":"user-guide/core-concepts/#summary","title":"Summary","text":"<p>ARC's architecture achieves Kubernetes-native artifact management through:</p> <ol> <li>Extension API Server: Provides declarative resource model with flexible storage backend</li> <li>Controller Pattern: OrderReconciler decomposes high-level Orders into executable Fragments</li> <li>Argo Integration: Leverages proven workflow engine for artifact processing</li> <li>Dedicated Storage: Isolated etcd prevents impact on cluster control plane</li> <li>Resource Model: Clean separation between configuration (Endpoint, ATD) and operations (Order, Fragment)</li> </ol>"},{"location":"user-guide/custom-resources/order/","title":"Order Resource","text":""},{"location":"user-guide/custom-resources/order/#order-resource","title":"Order Resource","text":"<p>The <code>Order</code> resource is the primary user-facing interface for requesting artifact operations. It allows users to declare multiple artifacts with shared default configurations.</p>"},{"location":"user-guide/custom-resources/order/#structure","title":"Structure","text":"<pre><code>apiVersion: arc.bwi.de/v1alpha1\nkind: Order\nmetadata:\n  name: example-order\n  namespace: default\nspec:\n  defaults:\n    srcRef:\n      name: docker-hub\n    dstRef:\n      name: internal-registry\n  artifacts:\n    - type: oci\n      spec:\n        image: library/alpine:3.18\n    - type: oci\n      dstRef:\n        name: other-registry\n      spec:\n        image: library/ubuntu:1.0\nstatus:\n  fragments:\n    \"abc123\": {name: \"example-order-abc123\"}\n    \"def456\": {name: \"example-order-def456\"}\n</code></pre>"}]}